{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "- used with sequential data (time series, sentences...)\n",
    "\n",
    "- parameters: input weights $\\mathbf{W}_i$, hidden weights $\\mathbf{W}_h$ and output weights $\\mathbf{W}_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{z}_t = \\mathbf{h}_{t-1} \\cdot \\mathbf{W}_h + \\mathbf{x} \\cdot \\mathbf{W}_i + \\mathbf{b}_i$$\n",
    "$$\\mathbf{h}_{t} = \\phi(\\mathbf{z}_t)$$\n",
    "$$\\mathbf{y}_t = \\mathbf{h}_{t} \\cdot \\mathbf{W}_o + \\mathbf{b}_o$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients\n",
    "\n",
    "$$\\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{h}_{t-1}} = \\mathbf{W}_h \\quad \\quad \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{W}_h} = \\mathbf{h}_{t-1} \\quad \\quad \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{x}} = \\mathbf{W}_i \\quad \\quad \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{W}_i} = \\mathbf{x} \\quad \\quad \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{b}_i} = 1$$\n",
    "\n",
    "$$\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{z}_t} = \\phi'(\\mathbf{z}_t)$$\n",
    "\n",
    "$$\\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{h}_{t}} = \\mathbf{W}_o \\quad \\quad \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{W}_o} = \\mathbf{h}_{t} \\quad \\quad \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{b}_o} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_o} &= \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\cdot \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{W}_o} \\\\\n",
    "&= \\delta_t \\cdot \\mathbf{h}_t\n",
    "\\end{aligned} \\quad \\quad\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_o} = \\sum_t \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_o}\n",
    "\\end{aligned}\n",
    "\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{b}_o} &= \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\cdot \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{b}_o} \\\\\n",
    "&= \\delta_t \\cdot 1 \\\\\n",
    "&= \\delta_t\n",
    "\n",
    "\\end{aligned} \\quad \\quad\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_o} = \\sum_t \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{b}_o}\n",
    "\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_h} &= \\left( \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\cdot \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{h}_{t}} + \\mathbf{g}_{t+1} \\cdot \\frac{\\partial \\mathbf{z}_{t+1}}{\\partial \\mathbf{h}_{t}} \\right) \\cdot \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{z}_t} \\cdot \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{W}_h} \\\\\n",
    "\n",
    "&= \\left( \\delta_t \\cdot \\mathbf{W}_o + \\mathbf{g}_{t+1} \\cdot \\mathbf{W}_h \\right) \\cdot \\phi'(\\mathbf{z}_t)\\cdot \\mathbf{h}_{t-1} \\\\\n",
    "\n",
    "&= \\left[\\mathbf{d}_t \\odot \\phi'(\\mathbf{z}_t) \\right] \\cdot \\mathbf{h}_{t-1} \\\\\n",
    "\n",
    "&= \\mathbf{g}_t \\cdot \\mathbf{h}_{t-1}\n",
    "\n",
    "\\end{aligned} \\quad \\quad\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_h} = \\sum_t \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_h}\n",
    "\\end{aligned}\n",
    "\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_i} &= \\left( \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\cdot \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{h}_{t}} + \\mathbf{g}_{t+1} \\cdot \\frac{\\partial \\mathbf{z}_{t+1}}{\\partial \\mathbf{h}_{t}} \\right) \\cdot \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{z}_t} \\cdot \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{W}_i} \\\\\n",
    "\n",
    "&= \\left( \\delta_t \\cdot \\mathbf{W}_o + \\mathbf{g}_{t+1} \\cdot \\mathbf{W}_h \\right) \\cdot \\phi'(\\mathbf{z}_t)\\cdot \\mathbf{x}_{t} \\\\\n",
    "\n",
    "&= \\left[\\mathbf{d}_t \\odot \\phi'(\\mathbf{z}_t) \\right] \\cdot \\mathbf{x}_{t} \\\\\n",
    "\n",
    "&= \\mathbf{g}_t \\cdot \\mathbf{x}_{t}\n",
    "\n",
    "\\end{aligned} \\quad \\quad\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_i} = \\sum_t \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}_i}\n",
    "\\end{aligned}\n",
    "\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{b}_i} &= \\left( \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\cdot \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{h}_{t}} + \\mathbf{g}_{t+1} \\cdot \\frac{\\partial \\mathbf{z}_{t+1}}{\\partial \\mathbf{h}_{t}} \\right) \\cdot \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{z}_t} \\cdot \\frac{\\partial \\mathbf{z}_t}{\\partial \\mathbf{b}_i} \\\\\n",
    "\n",
    "&= \\left( \\delta_t \\cdot \\mathbf{W}_o + \\mathbf{g}_{t+1} \\cdot \\mathbf{W}_h \\right) \\cdot \\phi'(\\mathbf{z}_t)\\cdot 1 \\\\\n",
    "\n",
    "&= \\mathbf{d}_t \\odot \\phi'(\\mathbf{z}_t) \\\\\n",
    "\n",
    "&= \\mathbf{g}_t\n",
    "\n",
    "\\end{aligned} \\quad \\quad\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_i} = \\sum_t \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{b}_i}\n",
    "\\end{aligned}\n",
    "\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentLayer:\n",
    "\n",
    "    def __init__(self, n_inputs: int, n_hidden: int, n_outputs: int):\n",
    "        k = 1/np.sqrt(n_hidden)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.input_weights = np.random.rand(n_inputs, n_hidden) * 2 * k - k\n",
    "        self.hidden_weights = np.random.rand(n_hidden, n_hidden) * 2 * k - k\n",
    "        self.output_weights = np.random.rand(n_hidden, n_outputs) * 2 * k - k\n",
    "        self.output_bias = np.random.rand(n_outputs) * 2 * k - k\n",
    "        self.input_bias = np.random.rand(n_hidden) * 2 * k - k\n",
    "        \n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        self.inputs = inputs\n",
    "        self.n_samples = inputs.shape[0]\n",
    "        self.output = np.zeros((self.n_samples, self.output_weights.shape[1]))\n",
    "        self.hidden_states = np.zeros((self.n_samples, self.n_hidden))\n",
    "\n",
    "        for idx, x in enumerate(inputs):\n",
    "\n",
    "            x = x.reshape(1, -1)\n",
    "\n",
    "            input_x = np.dot(x, self.input_weights)\n",
    "\n",
    "            hidden_x = input_x + np.dot(self.hidden_states[max(idx-1, 0)], self.hidden_weights) + self.input_bias\n",
    "            hidden_x = np.tanh(hidden_x)\n",
    "            self.hidden_states[idx] = hidden_x.copy()\n",
    "\n",
    "            output_x = np.dot(hidden_x, self.output_weights) + self.output_bias\n",
    "            self.output[idx] = output_x.copy()\n",
    "\n",
    "    def backward(self, delta: np.ndarray):\n",
    "\n",
    "        self.dinput_weights = np.zeros_like(self.input_weights)\n",
    "        self.dhidden_weights = np.zeros_like(self.hidden_weights)\n",
    "        self.dinput_bias = np.zeros_like(self.input_bias)\n",
    "        self.doutput_weights = np.zeros_like(self.output_weights)\n",
    "        self.doutput_bias = np.zeros_like(self.output_bias)\n",
    "        self.dinputs = np.zeros_like(self.inputs, dtype=np.float64)\n",
    "        next_hidden = None\n",
    "\n",
    "        for t in range(self.n_samples - 1, -1, -1):\n",
    "\n",
    "            loss_gradient = delta[t].reshape(1, -1)\n",
    "            hidden_state = self.hidden_states[t].reshape(-1, 1)\n",
    "\n",
    "            self.doutput_weights += np.dot(hidden_state, loss_gradient)\n",
    "            self.doutput_bias += loss_gradient.reshape(-1)\n",
    "\n",
    "            hidden_gradient = np.dot(loss_gradient, self.output_weights.T)\n",
    "            if next_hidden is not None:\n",
    "                hidden_gradient += np.dot(next_hidden, self.hidden_weights.T)\n",
    "\n",
    "            dtanh = 1 - self.hidden_states[t]**2\n",
    "            hidden_gradient *= dtanh\n",
    "\n",
    "            next_hidden = hidden_gradient.copy()\n",
    "\n",
    "            if t > 0:\n",
    "                self.dhidden_weights += np.dot(self.hidden_states[t-1].reshape(-1, 1), hidden_gradient)\n",
    "\n",
    "            self.dinput_weights += np.dot(self.inputs[t].reshape(-1, 1), hidden_gradient)\n",
    "            self.dinput_bias += hidden_gradient.reshape(-1)\n",
    "            \n",
    "            self.dinputs[t] += np.dot(self.input_weights, hidden_gradient.T).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(y_pred, y_true):\n",
    "    return (y_pred - y_true)\n",
    "\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return np.mean(0.5 * (y_pred - y_true)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_recurrent_layer(layer, lr, momentum=0.9):\n",
    "    \"\"\"layer.input_weights += -lr * layer.dinput_weights\n",
    "    layer.hidden_weights += -lr * layer.dhidden_weights\n",
    "    layer.hidden_biases += -lr * layer.dhidden_biases\n",
    "    layer.output_weights += -lr * layer.doutput_weights\n",
    "    layer.output_bias += -lr * layer.doutput_bias\"\"\"\n",
    "\n",
    "    if momentum:\n",
    "\n",
    "        if not hasattr(layer, 'input_weights_momentum'):\n",
    "            layer.input_weights_momentum = np.zeros_like(layer.input_weights)\n",
    "            layer.hidden_weights_momentum = np.zeros_like(layer.hidden_weights)\n",
    "            layer.output_weights_momentum = np.zeros_like(layer.output_weights)\n",
    "            layer.output_bias_momentum = np.zeros_like(layer.output_bias)\n",
    "            layer.input_bias_momentum = np.zeros_like(layer.input_bias)\n",
    "\n",
    "        layer.input_weights_momentum = momentum * layer.input_weights_momentum - lr * layer.dinput_weights\n",
    "        dinput_weights_updates = layer.input_weights_momentum\n",
    "\n",
    "        layer.hidden_weights_momentum = momentum * layer.hidden_weights_momentum - lr * layer.dhidden_weights\n",
    "        dhidden_weights_updates = layer.hidden_weights_momentum\n",
    "\n",
    "        layer.output_weights_momentum = momentum * layer.output_weights_momentum - lr * layer.doutput_weights\n",
    "        doutput_weights_updates = layer.output_weights_momentum\n",
    "\n",
    "        layer.output_bias_momentum = momentum * layer.output_bias_momentum - lr * layer.doutput_bias\n",
    "        doutput_bias_updates = layer.output_bias_momentum\n",
    "\n",
    "        layer.input_bias_momentum = momentum * layer.input_bias_momentum - lr * layer.dinput_bias\n",
    "        dinput_bias_updates = layer.input_bias_momentum\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        dinput_weights_updates = - lr * layer.dinput_weights\n",
    "\n",
    "        dhidden_weights_updates =  -lr * layer.dhidden_weights\n",
    "\n",
    "        doutput_weights_updates = - lr * layer.doutput_weights\n",
    "\n",
    "        doutput_bias_updates = - lr * layer.doutput_bias\n",
    "\n",
    "        dinput_bias_updates = - lr * layer.dinput_bias\n",
    "\n",
    "    layer.input_weights += dinput_weights_updates\n",
    "    layer.hidden_weights += dhidden_weights_updates\n",
    "    layer.input_bias += dinput_bias_updates\n",
    "    layer.output_weights += doutput_weights_updates\n",
    "    layer.output_bias += doutput_bias_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 641.4295974443879\n",
      "Loss 2: 582.2808127930862\n",
      "Loss 1: 2.278011331045261\n",
      "Loss 2: 2.356390502453872\n",
      "Loss 1: 2.244332611170712\n",
      "Loss 2: 2.2603650494965044\n",
      "Loss 1: 2.242822600390181\n",
      "Loss 2: 2.252173115395604\n",
      "Loss 1: 2.236721500567034\n",
      "Loss 2: 2.2464579462336025\n",
      "[52.86525189 52.93442906 52.93389858 52.9336197  52.93332997 52.93295864\n",
      " 52.93248346 52.93188872 52.93113802 52.93017165]\n",
      "[60 52 52 53 52 50 52 56 54 57]\n",
      "[52.85779326 52.92445304 52.92346299 52.92434006 52.9245707  52.92409876\n",
      " 52.92292779 52.92115118 52.9185935  52.91504262]\n",
      "[60 52 52 53 52 50 52 56 54 57]\n"
     ]
    }
   ],
   "source": [
    "# seed 0, lr=5e-4, backward konvergira\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rec11 = RecurrentLayer(1, 5, 1)\n",
    "rec21 = RecurrentLayer(1, 7, 1)\n",
    "\n",
    "rec12 = RecurrentLayer(1, 5, 1)\n",
    "rec22 = RecurrentLayer(1, 7, 1)\n",
    "\n",
    "sequence = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "sequence = scaler.fit_transform(sequence)\n",
    "result = np.array([60, 52, 52, 53, 52, 50, 52, 56, 54, 57]).reshape(-1, 1)\n",
    "lr = 5e-3\n",
    "seq_len = 3\n",
    "\n",
    "for i in range(500):\n",
    "\n",
    "    for j in range(len(sequence)-seq_len):\n",
    "\n",
    "        rec11.forward(sequence[j:j+seq_len, :])\n",
    "        rec21.forward(rec11.output)\n",
    "\n",
    "        rec12.forward(sequence[j:j+seq_len, :])\n",
    "        rec22.forward(rec12.output)\n",
    "\n",
    "        loss_grad_1 = mse_grad(rec21.output.reshape(-1, 1), result[j:j+seq_len, :])\n",
    "        loss_grad_2 = mse_grad(rec22.output.reshape(-1, 1), result[j:j+seq_len, :])\n",
    "\n",
    "        rec21.backward(loss_grad_1)\n",
    "        rec11.backward(rec21.dinputs)\n",
    "\n",
    "        rec22.backward(loss_grad_2)\n",
    "        rec12.backward(rec22.dinputs)\n",
    "\n",
    "        \"\"\"if i % 1000 == 0:\n",
    "            norme11 = []\n",
    "            norme12 = []\n",
    "            norme21 = []\n",
    "            norme22 = []\n",
    "            for l in [rec11.input_weights, \n",
    "                    rec11.hidden_weights, \n",
    "                    rec11.output_weights, \n",
    "                    rec11.output_bias, \n",
    "                    rec11.hidden_biases, \n",
    "                    rec11.hidden_states]:\n",
    "                norme11.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec12.input_weights, \n",
    "                    rec12.hidden_weights, \n",
    "                    rec12.output_weights, \n",
    "                    rec12.output_bias, \n",
    "                    rec12.hidden_biases, \n",
    "                    rec12.hidden_states]:\n",
    "                norme12.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec21.input_weights, \n",
    "                    rec21.hidden_weights, \n",
    "                    rec21.output_weights, \n",
    "                    rec21.output_bias, \n",
    "                    rec21.hidden_biases, \n",
    "                    rec21.hidden_states]:\n",
    "                norme21.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec22.input_weights, \n",
    "                    rec22.hidden_weights, \n",
    "                    rec22.output_weights, \n",
    "                    rec22.output_bias, \n",
    "                    rec22.hidden_biases, \n",
    "                    rec22.hidden_states]:\n",
    "                norme22.append(np.linalg.norm(l))\n",
    "\n",
    "            norme11 = np.array(norme11)\n",
    "            norme12 = np.array(norme12)\n",
    "            norme21 = np.array(norme21)\n",
    "            norme22 = np.array(norme22)\n",
    "\n",
    "            print(f'Razlike 1: {np.abs(norme11 - norme12)}')\n",
    "            print(f'Razlike 2: {np.abs(norme21 - norme22)}')\"\"\"\n",
    "\n",
    "        update_recurrent_layer(rec11, lr, momentum=0)\n",
    "        update_recurrent_layer(rec12, lr, momentum=0)\n",
    "        update_recurrent_layer(rec21, lr, momentum=0)\n",
    "        update_recurrent_layer(rec22, lr, momentum=0)\n",
    "\n",
    "    #print(f'dInput weights: {np.linalg.norm(rec11.dinput_weights)}, dhidden weights: {np.linalg.norm(rec11.dhidden_weights)}, doutput weights: {np.linalg.norm(rec11.doutput_weights)}')\n",
    "    #print(f'dInput weights: {np.linalg.norm(rec12.dinput_weights)}, dhidden weights: {np.linalg.norm(rec12.dhidden_weights)}, doutput weights: {np.linalg.norm(rec12.doutput_weights)}')\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss 1: {mse_loss(rec21.output.reshape(-1, 1), result[j:j+seq_len, :])}')\n",
    "        print(f'Loss 2: {mse_loss(rec22.output.reshape(-1, 1), result[j:j+seq_len, :])}')\n",
    "\n",
    "rec11.forward(sequence)\n",
    "rec21.forward(rec11.output)\n",
    "print(rec21.output.reshape(-1))\n",
    "print(result.reshape(-1))\n",
    "\n",
    "rec12.forward(sequence)\n",
    "rec22.forward(rec12.output)\n",
    "print(rec22.output.reshape(-1))\n",
    "print(result.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>rain</th>\n",
       "      <th>tmax_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-03</td>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-04</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13504</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13506</th>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>70.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13508</th>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13509 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  tmax  tmin  rain  tmax_tomorrow\n",
       "0      1970-01-01  60.0  35.0   0.0           52.0\n",
       "1      1970-01-02  52.0  39.0   0.0           52.0\n",
       "2      1970-01-03  52.0  35.0   0.0           53.0\n",
       "3      1970-01-04  53.0  36.0   0.0           52.0\n",
       "4      1970-01-05  52.0  35.0   0.0           50.0\n",
       "...           ...   ...   ...   ...            ...\n",
       "13504  2022-11-22  62.0  35.0   0.0           67.0\n",
       "13505  2022-11-23  67.0  38.0   0.0           66.0\n",
       "13506  2022-11-24  66.0  41.0   0.0           70.0\n",
       "13507  2022-11-25  70.0  39.0   0.0           62.0\n",
       "13508  2022-11-26  62.0  41.0   0.0           64.0\n",
       "\n",
       "[13509 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('clean_weather.csv', names=['date', 'tmax', 'tmin', 'rain', 'tmax_tomorrow'], header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (13509, 3)\n",
      "y: (13509,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FEATURES = ['tmax', 'tmin', 'rain']\n",
    "TARGET = 'tmax_tomorrow'\n",
    "\n",
    "X = data[FEATURES].to_numpy()\n",
    "y = data[TARGET].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (675, 3), y_train: (675,)\n",
      "X_test: (12834, 3), y_test: (12834,)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05\n",
    "\n",
    "X_train = X[:int(threshold*len(X)),:].copy()\n",
    "y_train = y[:int(threshold*len(X))].copy()\n",
    "\n",
    "X_test = X[int(threshold*len(X)):,:].copy()\n",
    "y_test = y[int(threshold*len(X)):].copy()\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss 0: 59.36530548954579\n",
      "dInput weights: 9.23545522609929, dhidden weights: 0.1513727467003833, doutput weights: 28.82272775042941\n",
      "dInput weights: 11.345237196157536, dhidden weights: 0.15317013284321307, doutput weights: 28.640884976196464\n",
      "dInput weights: 22.20137239826506, dhidden weights: 11.01622715347365, doutput weights: 24.899365387596344\n",
      "dInput weights: 208.3497272776964, dhidden weights: 265.9011302523748, doutput weights: 48.020292475543805\n",
      "dInput weights: 199.9357852803011, dhidden weights: 260.83423880394275, doutput weights: 33.099591390073336\n",
      "dInput weights: 8.717254557444894, dhidden weights: 14.40671154896009, doutput weights: 1.8139007252136974\n",
      "dInput weights: 11.182873516487751, dhidden weights: 23.661544066362083, doutput weights: 2.068362157527905\n",
      "dInput weights: 20.82655503467082, dhidden weights: 43.00056654070374, doutput weights: 4.355895308117471\n",
      "dInput weights: 25.260385598948407, dhidden weights: 54.335149147697955, doutput weights: 5.3328379391260015\n",
      "dInput weights: 27.11120734364897, dhidden weights: 56.34213586597694, doutput weights: 5.66356070042377\n",
      "Epoch loss 10: 13.147664018964624\n",
      "dInput weights: 28.64264273976489, dhidden weights: 58.29798918273996, doutput weights: 5.941522782003842\n",
      "dInput weights: 29.35271508454542, dhidden weights: 59.098457410285555, doutput weights: 6.0697430125866285\n",
      "dInput weights: 27.133304540703932, dhidden weights: 56.222078726708546, doutput weights: 5.697828506545096\n",
      "dInput weights: 19.733884943834745, dhidden weights: 47.35449433833141, doutput weights: 4.248764761623044\n",
      "dInput weights: 30.173107096276535, dhidden weights: 60.0389030589291, doutput weights: 6.2003445377200155\n",
      "dInput weights: 28.455266284501793, dhidden weights: 58.03616122013493, doutput weights: 5.903720811711491\n",
      "dInput weights: 29.620990511301386, dhidden weights: 59.396421358391194, doutput weights: 6.10832540298762\n",
      "dInput weights: 29.087534191036582, dhidden weights: 58.76504115990495, doutput weights: 6.017435560062553\n",
      "dInput weights: 29.68131007926695, dhidden weights: 59.42182434101776, doutput weights: 6.121802812533673\n",
      "dInput weights: 29.05824939326243, dhidden weights: 58.63565004782785, doutput weights: 6.017030119281487\n",
      "Epoch loss 20: 13.141362272108513\n",
      "dInput weights: 22.909643585973175, dhidden weights: 50.03505376758903, doutput weights: 4.943632712013974\n",
      "dInput weights: 11.99437322411411, dhidden weights: 30.344777551282505, doutput weights: 2.401773543710707\n",
      "dInput weights: 12.97943495316053, dhidden weights: 28.290039030150517, doutput weights: 1.1985871960848893\n",
      "dInput weights: 11.727953484168847, dhidden weights: 28.489952035975318, doutput weights: 1.5957828653355663\n",
      "dInput weights: 11.405437582262289, dhidden weights: 27.32741301186739, doutput weights: 1.5284969448088668\n",
      "dInput weights: 15.06832255230606, dhidden weights: 38.534349874089756, doutput weights: 3.2836837745419847\n",
      "dInput weights: 16.208577296875063, dhidden weights: 37.7727908268693, doutput weights: 3.560199298454268\n",
      "dInput weights: 24.199027426121695, dhidden weights: 53.07557822588447, doutput weights: 5.164501615415389\n",
      "dInput weights: 28.437053203427244, dhidden weights: 57.98418782499702, doutput weights: 5.929365292284247\n",
      "dInput weights: 27.236823907224434, dhidden weights: 55.46055494718231, doutput weights: 5.73997822774846\n",
      "Epoch loss 30: 13.104934536962052\n",
      "dInput weights: 20.706620928800593, dhidden weights: 48.20121233340795, doutput weights: 4.490385214695529\n",
      "dInput weights: 13.706468895836538, dhidden weights: 36.46938227671123, doutput weights: 2.964289972883106\n",
      "dInput weights: 14.69715798670498, dhidden weights: 37.68918166292799, doutput weights: 3.059622194386203\n",
      "dInput weights: 17.104904299385115, dhidden weights: 43.00549648778007, doutput weights: 3.673878018692772\n",
      "dInput weights: 16.469856011240022, dhidden weights: 38.48904101946477, doutput weights: 3.5076269624663974\n",
      "dInput weights: 12.209327854483318, dhidden weights: 32.31929441295883, doutput weights: 2.2757040404807554\n",
      "dInput weights: 10.672193464884723, dhidden weights: 25.949081701444786, doutput weights: 1.6888290330357796\n",
      "dInput weights: 14.164869518114934, dhidden weights: 37.703624075492016, doutput weights: 2.7890622741202358\n",
      "dInput weights: 25.897417317056973, dhidden weights: 53.203071242685525, doutput weights: 5.381977468800449\n",
      "dInput weights: 30.420162699679796, dhidden weights: 60.18231396394136, doutput weights: 6.236079625594017\n",
      "Epoch loss 40: 13.158252786414709\n",
      "dInput weights: 29.466398540529326, dhidden weights: 59.07995835248416, doutput weights: 6.074837391285286\n",
      "dInput weights: 24.992836034872795, dhidden weights: 50.94522889019838, doutput weights: 5.193026365822858\n",
      "dInput weights: 28.98798172231255, dhidden weights: 58.325603734841096, doutput weights: 6.000014599224022\n",
      "dInput weights: 27.22908513969684, dhidden weights: 55.01266784838936, doutput weights: 5.706816662493061\n",
      "dInput weights: 18.878351962763116, dhidden weights: 39.62774460234341, doutput weights: 4.041792992599158\n",
      "dInput weights: 20.92165544313562, dhidden weights: 48.58385301434002, doutput weights: 4.459925151776409\n",
      "dInput weights: 29.925369736399016, dhidden weights: 59.664225954667025, doutput weights: 6.15065255043115\n",
      "dInput weights: 29.689821956354557, dhidden weights: 59.38648800045978, doutput weights: 6.11092680924571\n",
      "dInput weights: 29.070426999522237, dhidden weights: 58.664284457645294, doutput weights: 6.004150914307732\n",
      "dInput weights: 30.145794629236374, dhidden weights: 59.90621737027268, doutput weights: 6.191013990493285\n",
      "Epoch loss 50: 13.28331110393594\n",
      "dInput weights: 24.408983617081862, dhidden weights: 49.17923044516426, doutput weights: 5.0481338386777175\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "rec1 = RecurrentLayer(3, 4, 1)\n",
    "\n",
    "lr = 1e-3\n",
    "seq_len = 7\n",
    "\n",
    "for i in range(51):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for j in range(len(X_train) - seq_len):\n",
    "\n",
    "        rec1.forward(X_train[j:j+seq_len, :])\n",
    "\n",
    "        epoch_loss += mse_loss(rec1.output, y_train[j:j+seq_len])\n",
    "\n",
    "        loss_grad = mse_grad(rec1.output.reshape(-1), y_train[j:j+seq_len])\n",
    "\n",
    "        rec1.backward(loss_grad)\n",
    "\n",
    "        update_recurrent_layer(rec1, lr, momentum=0.)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch loss {i}: {epoch_loss / len(X_train)}')\n",
    "\n",
    "    print(f'dInput weights: {np.linalg.norm(rec1.dinput_weights)}, dhidden weights: {np.linalg.norm(rec1.dhidden_weights)}, doutput weights: {np.linalg.norm(rec1.doutput_weights)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.15515683 67.01852578 62.59179562 65.16812513]\n",
      "[65. 62. 63. 67.]\n",
      "Loss: 3.6777196676920982\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "start = randint(0, len(X_test))\n",
    "seq_len = 4\n",
    "rec1.forward(X_test[start:start+seq_len, :])\n",
    "print(rec1.output.reshape(-1))\n",
    "print(y_test.reshape(-1)[start:start+seq_len])\n",
    "print(f'Loss: {mse_loss(rec1.output.reshape(-1), y_test.reshape(-1)[start:start+seq_len])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
