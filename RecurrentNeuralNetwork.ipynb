{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "- used with sequential data (time series, sentences...)\n",
    "\n",
    "- parameters: input weights $\\mathbf{W}_i$, hidden weights $\\mathbf{W}_h$ and output weights $\\mathbf{W}_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass\n",
    "\n",
    "$$\\mathbf{z}_t = \\mathbf{h}_{t-1} \\cdot \\mathbf{W}_h + \\mathbf{x} \\cdot \\mathbf{W}_i$$\n",
    "$$\\mathbf{h}_{t} = \\phi(\\mathbf{z}_t)$$\n",
    "$$\\mathbf{y}_t = \\mathbf{h}_{t} \\cdot \\mathbf{W}_o$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "\n",
    "$$\\frac{\\partial X_i}{\\partial X} = W_i$$\n",
    "$$\\frac{\\partial X_i}{\\partial W_i} = X$$\n",
    "$$\\frac{\\partial X_h(t)}{\\partial X_i} = \\frac{\\partial \\phi}{\\partial Z} \\cdot \\frac{\\partial Z}{\\partial X_i} = \\frac{\\partial \\phi}{\\partial Z} \\cdot 1$$\n",
    "$$\\frac{\\partial X_h(t)}{\\partial W_h} = \\frac{\\partial \\phi}{\\partial Z} \\cdot \\frac{\\partial Z}{\\partial W_h} = \\frac{\\partial \\phi}{\\partial Z} \\cdot X_h(t-1)$$\n",
    "$$\\frac{\\partial X_h(t)}{\\partial X_h(t-1)} = \\frac{\\partial \\phi}{\\partial Z} \\cdot \\frac{\\partial Z}{\\partial X_h(t-1)} = \\frac{\\partial \\phi}{\\partial Z} \\cdot W_h$$\n",
    "$$\\frac{\\partial Y}{\\partial X_h(t)} = W_0$$\n",
    "$$\\frac{\\partial Y}{\\partial W_o} = X_h(t)$$\n",
    "\n",
    "***\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W_o} &= \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial W_o} \\\\\n",
    "&= \\frac{\\partial L}{\\partial Y} \\cdot X_h(t)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W_h} &= \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial X_h(t)} \\cdot \\frac{\\partial X_h(t)}{\\partial W_h} \\\\\n",
    "&= \\frac{\\partial L}{\\partial Y} \\cdot W_o \\cdot \\frac{\\partial \\phi}{\\partial Z} \\cdot X_h(t-1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W_i} &= \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial X_h(t)} \\cdot \\frac{\\partial X_h(t)}{\\partial X_i} \\cdot \\frac{\\partial X_i}{\\partial W_i} \\\\\n",
    "&= \\frac{\\partial L}{\\partial Y} \\cdot W_o \\cdot \\frac{\\partial \\phi}{\\partial Z} \\cdot 1 \\cdot X\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial X} &= \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial X_h(t)} \\cdot \\frac{\\partial X_h(t)}{\\partial X_i} \\cdot \\frac{\\partial X_i}{\\partial X} \\\\\n",
    "&= \\frac{\\partial L}{\\partial Y} \\cdot W_o \\cdot \\frac{\\partial \\phi}{\\partial Z} \\cdot 1 \\cdot W_i\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentLayer:\n",
    "\n",
    "    def __init__(self, n_inputs: int, n_hidden: int, n_outputs: int):\n",
    "        k = 1/np.sqrt(n_hidden)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.input_weights = np.random.rand(n_inputs, n_hidden) * 2 * k - k\n",
    "        self.hidden_weights = np.random.rand(n_hidden, n_hidden) * 2 * k - k\n",
    "        self.output_weights = np.random.rand(n_hidden, n_outputs) * 2 * k - k\n",
    "        self.output_bias = np.random.rand(n_outputs) * 2 * k - k\n",
    "        self.hidden_biases = np.random.rand(n_hidden) * 2 * k - k\n",
    "        \n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        self.inputs = inputs\n",
    "        self.n_samples = inputs.shape[0]\n",
    "        self.output = np.zeros((self.n_samples, self.output_weights.shape[1]))\n",
    "        self.hidden_states = np.zeros((self.n_samples, self.n_hidden))\n",
    "\n",
    "        for idx, x in enumerate(inputs):\n",
    "\n",
    "            x = x.reshape(1, -1)\n",
    "\n",
    "            input_x = np.dot(x, self.input_weights)\n",
    "\n",
    "            hidden_x = input_x + np.dot(self.hidden_states[max(idx-1, 0)], self.hidden_weights) + self.hidden_biases\n",
    "            hidden_x = np.tanh(hidden_x)\n",
    "            self.hidden_states[idx] = hidden_x.copy()\n",
    "\n",
    "            output_x = np.dot(hidden_x, self.output_weights) + self.output_bias\n",
    "            self.output[idx] = output_x.copy()\n",
    "\n",
    "    def backward(self, delta: np.ndarray):\n",
    "\n",
    "        self.dinput_weights = np.zeros_like(self.input_weights)\n",
    "        self.dhidden_weights = np.zeros_like(self.hidden_weights)\n",
    "        self.dhidden_biases = np.zeros_like(self.hidden_biases)\n",
    "        self.doutput_weights = np.zeros_like(self.output_weights)\n",
    "        self.doutput_bias = np.zeros_like(self.output_bias)\n",
    "        self.dinputs = np.zeros_like(self.inputs, dtype=np.float64)\n",
    "        next_hidden = None\n",
    "\n",
    "        for i in range(self.n_samples - 1, -1, -1):\n",
    "\n",
    "            loss_gradient = delta[i].reshape(1, -1)\n",
    "            hidden_state = self.hidden_states[i].reshape(-1, 1)\n",
    "\n",
    "            self.doutput_weights += np.dot(hidden_state, loss_gradient)\n",
    "            self.doutput_bias += loss_gradient.reshape(-1)\n",
    "\n",
    "            hidden_gradient = np.dot(loss_gradient, self.output_weights.T)\n",
    "            if next_hidden is not None:\n",
    "                hidden_gradient += np.dot(next_hidden, self.hidden_weights.T)\n",
    "\n",
    "            dtanh = 1 - self.hidden_states[i]**2\n",
    "            hidden_gradient *= dtanh\n",
    "\n",
    "            next_hidden = hidden_gradient.copy()\n",
    "\n",
    "            if i > 0:\n",
    "                self.dhidden_weights += np.dot(self.hidden_states[i-1].reshape(-1, 1), hidden_gradient) #self.hidden_states[i - 1].reshape(-1, 1) @ h_grad\n",
    "                self.dhidden_biases += hidden_gradient.reshape(-1)\n",
    "                self.dinput_weights += np.dot(self.inputs[i].reshape(-1, 1), hidden_gradient) #self.inputs[i].reshape(-1, 1) @ h_grad\n",
    "\n",
    "            self.dinputs[i] += np.dot(self.input_weights, hidden_gradient.T).reshape(-1) #(self.input_weights @ h_grad.T).item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(y_pred, y_true):\n",
    "    return (y_pred - y_true)\n",
    "\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return np.mean(0.5 * (y_pred - y_true)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_recurrent_layer(layer, lr, momentum=0.9):\n",
    "    \"\"\"layer.input_weights += -lr * layer.dinput_weights\n",
    "    layer.hidden_weights += -lr * layer.dhidden_weights\n",
    "    layer.hidden_biases += -lr * layer.dhidden_biases\n",
    "    layer.output_weights += -lr * layer.doutput_weights\n",
    "    layer.output_bias += -lr * layer.doutput_bias\"\"\"\n",
    "\n",
    "    if momentum:\n",
    "\n",
    "        if not hasattr(layer, 'input_weights_momentum'):\n",
    "            layer.input_weights_momentum = np.zeros_like(layer.input_weights)\n",
    "            layer.hidden_weights_momentum = np.zeros_like(layer.hidden_weights)\n",
    "            layer.output_weights_momentum = np.zeros_like(layer.output_weights)\n",
    "            layer.output_bias_momentum = np.zeros_like(layer.output_bias)\n",
    "            layer.hidden_biases_momentum = np.zeros_like(layer.hidden_biases)\n",
    "\n",
    "        layer.input_weights_momentum = momentum * layer.input_weights_momentum - lr * layer.dinput_weights\n",
    "        dinput_weights_updates = layer.input_weights_momentum\n",
    "\n",
    "        layer.hidden_weights_momentum = momentum * layer.hidden_weights_momentum - lr * layer.dhidden_weights\n",
    "        dhidden_weights_updates = layer.hidden_weights_momentum\n",
    "\n",
    "        layer.output_weights_momentum = momentum * layer.output_weights_momentum - lr * layer.doutput_weights\n",
    "        doutput_weights_updates = layer.output_weights_momentum\n",
    "\n",
    "        layer.output_bias_momentum = momentum * layer.output_bias_momentum - lr * layer.doutput_bias\n",
    "        doutput_bias_updates = layer.output_bias_momentum\n",
    "\n",
    "        layer.hidden_biases_momentum = momentum * layer.hidden_biases_momentum - lr * layer.dhidden_biases\n",
    "        dhidden_biases_updates = layer.hidden_biases_momentum\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        dinput_weights_updates = - lr * layer.dinput_weights\n",
    "\n",
    "        dhidden_weights_updates =  -lr * layer.dhidden_weights\n",
    "\n",
    "        doutput_weights_updates = - lr * layer.doutput_weights\n",
    "\n",
    "        doutput_bias_updates = - lr * layer.doutput_bias\n",
    "\n",
    "        dhidden_biases_updates = - lr * layer.dhidden_biases\n",
    "\n",
    "    layer.input_weights += dinput_weights_updates\n",
    "    layer.hidden_weights += dhidden_weights_updates\n",
    "    layer.hidden_biases += dhidden_biases_updates\n",
    "    layer.output_weights += doutput_weights_updates\n",
    "    layer.output_bias += doutput_bias_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 568.4424851446765\n",
      "Loss 2: 628.9403008649464\n",
      "Loss 1: 2.035433117532382\n",
      "Loss 2: 1.7851348236870457\n",
      "Loss 1: 2.3172628489620677\n",
      "Loss 2: 0.28974729190130327\n",
      "Loss 1: 2.2939677823039615\n",
      "Loss 2: 0.2786899329699611\n",
      "Loss 1: 2.23750998051382\n",
      "Loss 2: 0.05414823335795991\n",
      "[52.26466962 52.89462815 52.92358133 52.93036208 52.94258359 52.94787717\n",
      " 52.95245291 52.9545557  52.95594964 52.95654465]\n",
      "[60 52 52 53 52 50 52 56 54 57]\n",
      "[52.16317868 52.18469649 52.18464374 52.1845776  52.18445693 52.18414309\n",
      " 52.18290263 52.22170328 57.37013405 53.28353593]\n",
      "[60 52 52 53 52 50 52 56 54 57]\n"
     ]
    }
   ],
   "source": [
    "# seed 0, lr=5e-4, backward konvergira\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "rec11 = RecurrentLayer(1, 5, 1)\n",
    "rec21 = RecurrentLayer(1, 7, 1)\n",
    "\n",
    "rec12 = RecurrentLayer(1, 5, 1)\n",
    "rec22 = RecurrentLayer(1, 7, 1)\n",
    "\n",
    "sequence = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "sequence = scaler.fit_transform(sequence)\n",
    "result = np.array([60, 52, 52, 53, 52, 50, 52, 56, 54, 57]).reshape(-1, 1)\n",
    "lr = 5e-3\n",
    "seq_len = 3\n",
    "\n",
    "for i in range(500):\n",
    "\n",
    "    for j in range(len(sequence)-seq_len):\n",
    "\n",
    "        rec11.forward(sequence[j:j+seq_len, :])\n",
    "        rec21.forward(rec11.output)\n",
    "\n",
    "        rec12.forward(sequence[j:j+seq_len, :])\n",
    "        rec22.forward(rec12.output)\n",
    "\n",
    "        loss_grad_1 = mse_grad(rec21.output.reshape(-1, 1), result[j:j+seq_len, :])\n",
    "        loss_grad_2 = mse_grad(rec22.output.reshape(-1, 1), result[j:j+seq_len, :])\n",
    "\n",
    "        rec21.backward(loss_grad_1)\n",
    "        rec11.backward(rec21.dinputs)\n",
    "\n",
    "        rec22.backward(loss_grad_2)\n",
    "        rec12.backward(rec22.dinputs)\n",
    "\n",
    "        \"\"\"if i % 1000 == 0:\n",
    "            norme11 = []\n",
    "            norme12 = []\n",
    "            norme21 = []\n",
    "            norme22 = []\n",
    "            for l in [rec11.input_weights, \n",
    "                    rec11.hidden_weights, \n",
    "                    rec11.output_weights, \n",
    "                    rec11.output_bias, \n",
    "                    rec11.hidden_biases, \n",
    "                    rec11.hidden_states]:\n",
    "                norme11.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec12.input_weights, \n",
    "                    rec12.hidden_weights, \n",
    "                    rec12.output_weights, \n",
    "                    rec12.output_bias, \n",
    "                    rec12.hidden_biases, \n",
    "                    rec12.hidden_states]:\n",
    "                norme12.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec21.input_weights, \n",
    "                    rec21.hidden_weights, \n",
    "                    rec21.output_weights, \n",
    "                    rec21.output_bias, \n",
    "                    rec21.hidden_biases, \n",
    "                    rec21.hidden_states]:\n",
    "                norme21.append(np.linalg.norm(l))\n",
    "\n",
    "            for l in [rec22.input_weights, \n",
    "                    rec22.hidden_weights, \n",
    "                    rec22.output_weights, \n",
    "                    rec22.output_bias, \n",
    "                    rec22.hidden_biases, \n",
    "                    rec22.hidden_states]:\n",
    "                norme22.append(np.linalg.norm(l))\n",
    "\n",
    "            norme11 = np.array(norme11)\n",
    "            norme12 = np.array(norme12)\n",
    "            norme21 = np.array(norme21)\n",
    "            norme22 = np.array(norme22)\n",
    "\n",
    "            print(f'Razlike 1: {np.abs(norme11 - norme12)}')\n",
    "            print(f'Razlike 2: {np.abs(norme21 - norme22)}')\"\"\"\n",
    "\n",
    "        update_recurrent_layer(rec11, lr, momentum=0)\n",
    "        update_recurrent_layer(rec12, lr, momentum=0)\n",
    "        update_recurrent_layer(rec21, lr, momentum=0)\n",
    "        update_recurrent_layer(rec22, lr, momentum=0)\n",
    "\n",
    "    #print(f'dInput weights: {np.linalg.norm(rec11.dinput_weights)}, dhidden weights: {np.linalg.norm(rec11.dhidden_weights)}, doutput weights: {np.linalg.norm(rec11.doutput_weights)}')\n",
    "    #print(f'dInput weights: {np.linalg.norm(rec12.dinput_weights)}, dhidden weights: {np.linalg.norm(rec12.dhidden_weights)}, doutput weights: {np.linalg.norm(rec12.doutput_weights)}')\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss 1: {mse_loss(rec21.output.reshape(-1, 1), result[j:j+seq_len, :])}')\n",
    "        print(f'Loss 2: {mse_loss(rec22.output.reshape(-1, 1), result[j:j+seq_len, :])}')\n",
    "\n",
    "rec11.forward(sequence)\n",
    "rec21.forward(rec11.output)\n",
    "print(rec21.output.reshape(-1))\n",
    "print(result.reshape(-1))\n",
    "\n",
    "rec12.forward(sequence)\n",
    "rec22.forward(rec12.output)\n",
    "print(rec22.output.reshape(-1))\n",
    "print(result.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>rain</th>\n",
       "      <th>tmax_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-03</td>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-04</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13504</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13506</th>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>70.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13508</th>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13509 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  tmax  tmin  rain  tmax_tomorrow\n",
       "0      1970-01-01  60.0  35.0   0.0           52.0\n",
       "1      1970-01-02  52.0  39.0   0.0           52.0\n",
       "2      1970-01-03  52.0  35.0   0.0           53.0\n",
       "3      1970-01-04  53.0  36.0   0.0           52.0\n",
       "4      1970-01-05  52.0  35.0   0.0           50.0\n",
       "...           ...   ...   ...   ...            ...\n",
       "13504  2022-11-22  62.0  35.0   0.0           67.0\n",
       "13505  2022-11-23  67.0  38.0   0.0           66.0\n",
       "13506  2022-11-24  66.0  41.0   0.0           70.0\n",
       "13507  2022-11-25  70.0  39.0   0.0           62.0\n",
       "13508  2022-11-26  62.0  41.0   0.0           64.0\n",
       "\n",
       "[13509 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('clean_weather.csv', names=['date', 'tmax', 'tmin', 'rain', 'tmax_tomorrow'], header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (13509, 3)\n",
      "y: (13509,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FEATURES = ['tmax', 'tmin', 'rain']\n",
    "TARGET = 'tmax_tomorrow'\n",
    "\n",
    "X = data[FEATURES].to_numpy()\n",
    "y = data[TARGET].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (675, 3), y_train: (675,)\n",
      "X_test: (12834, 3), y_test: (12834,)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05\n",
    "\n",
    "X_train = X[:int(threshold*len(X)),:].copy()\n",
    "y_train = y[:int(threshold*len(X))].copy()\n",
    "\n",
    "X_test = X[int(threshold*len(X)):,:].copy()\n",
    "y_test = y[int(threshold*len(X)):].copy()\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss 0: 70.86887843368365\n",
      "dInput weights: 0.22876374089578788, dhidden weights: 0.34597162404873794, doutput weights: 35.200825515898245\n",
      "dInput weights: 0.3592668113932815, dhidden weights: 0.5234197358040739, doutput weights: 31.58690859835022\n",
      "dInput weights: 2.1543973605988183, dhidden weights: 2.65290353262858, doutput weights: 24.623665385862484\n",
      "dInput weights: 361.74004322415715, dhidden weights: 519.472237586879, doutput weights: 71.50236106670708\n",
      "dInput weights: 334.1185205370646, dhidden weights: 468.6662874727242, doutput weights: 83.23951245937046\n",
      "dInput weights: 253.28671419489206, dhidden weights: 355.9622585024941, doutput weights: 70.09075449646852\n",
      "dInput weights: 220.0948881176314, dhidden weights: 309.7607926087972, doutput weights: 64.10724901281382\n",
      "dInput weights: 196.19478151629727, dhidden weights: 276.33329595731726, doutput weights: 59.42537943163376\n",
      "dInput weights: 177.52280556260555, dhidden weights: 249.19489130390892, doutput weights: 54.53404332055495\n",
      "dInput weights: 160.16858057001758, dhidden weights: 223.46578639556216, doutput weights: 49.55075985243144\n",
      "Epoch loss 10: 15.284916723163379\n",
      "dInput weights: 127.22750243878262, dhidden weights: 174.29086692184057, doutput weights: 40.52830084472095\n",
      "dInput weights: 72.38026925421323, dhidden weights: 94.84803664130486, doutput weights: 28.47324246407744\n",
      "dInput weights: 6.434855291824239, dhidden weights: 6.567320292527915, doutput weights: 16.429241169053018\n",
      "dInput weights: 63.67875880433074, dhidden weights: 93.11067317632852, doutput weights: 7.933441864276761\n",
      "dInput weights: 48.253294934285194, dhidden weights: 71.31049896223762, doutput weights: 7.389205790128649\n",
      "dInput weights: 37.52226907630171, dhidden weights: 55.44159034220123, doutput weights: 5.481860952433226\n",
      "dInput weights: 77.23207070606111, dhidden weights: 113.03042211613267, doutput weights: 13.214281415062\n",
      "dInput weights: 37.79677717524831, dhidden weights: 59.31288320583023, doutput weights: 14.011769947320643\n",
      "dInput weights: 39.80677528810975, dhidden weights: 62.0308484072095, doutput weights: 13.508974929573805\n",
      "dInput weights: 39.168246761036, dhidden weights: 61.11668403389298, doutput weights: 13.505403496130688\n",
      "Epoch loss 20: 16.43656640552782\n",
      "dInput weights: 38.38921850837987, dhidden weights: 60.00172486983435, doutput weights: 13.512597503245068\n",
      "dInput weights: 37.73423201780222, dhidden weights: 59.04723857674114, doutput weights: 13.50256833156952\n",
      "dInput weights: 37.262274677643894, dhidden weights: 58.335313613673435, doutput weights: 13.467562973634735\n",
      "dInput weights: 36.96170638713888, dhidden weights: 57.850942720480006, doutput weights: 13.40774489133632\n",
      "dInput weights: 36.78807010213341, dhidden weights: 57.53307340347226, doutput weights: 13.32658340493469\n",
      "dInput weights: 36.733962929479794, dhidden weights: 57.37091282602395, doutput weights: 13.225273229237931\n",
      "dInput weights: 36.823182611740656, dhidden weights: 57.39751866968243, doutput weights: 13.100800178910143\n",
      "dInput weights: 37.208157262681134, dhidden weights: 57.82388283795908, doutput weights: 12.932309624838009\n",
      "dInput weights: 38.147049309155406, dhidden weights: 59.008877977294674, doutput weights: 12.689939223578651\n",
      "dInput weights: 39.65415010545997, dhidden weights: 60.97662589545624, doutput weights: 12.367468562212272\n",
      "Epoch loss 30: 16.12536674986687\n",
      "dInput weights: 40.06033047339695, dhidden weights: 61.41268461616177, doutput weights: 12.214029531049675\n",
      "dInput weights: 41.57796777290855, dhidden weights: 63.38776929776837, doutput weights: 11.887362135128125\n",
      "dInput weights: 42.09604252659445, dhidden weights: 63.96715009658049, doutput weights: 11.709408517802423\n",
      "dInput weights: 42.87646919208951, dhidden weights: 64.90715972062232, doutput weights: 11.478561413400193\n",
      "dInput weights: 43.3250507128692, dhidden weights: 65.37538596493651, doutput weights: 11.295293720756243\n",
      "dInput weights: 43.53378923640285, dhidden weights: 65.49727090951646, doutput weights: 11.137371787918749\n",
      "dInput weights: 43.73353939010998, dhidden weights: 65.5944188093034, doutput weights: 10.96252161540994\n",
      "dInput weights: 43.913733954858166, dhidden weights: 65.64650721919513, doutput weights: 10.780050004676895\n",
      "dInput weights: 44.28740664153298, dhidden weights: 65.94864876625215, doutput weights: 10.55327461687719\n",
      "dInput weights: 44.55091598115963, dhidden weights: 66.07375646730955, doutput weights: 10.320853165479901\n",
      "Epoch loss 40: 15.677978500443718\n",
      "dInput weights: 44.903155941310814, dhidden weights: 66.29198840066786, doutput weights: 10.048779406234582\n",
      "dInput weights: 45.27750422039664, dhidden weights: 66.50203329512625, doutput weights: 9.736122781009296\n",
      "dInput weights: 45.66734487584317, dhidden weights: 66.68072089133392, doutput weights: 9.367944109823805\n",
      "dInput weights: 46.06412735570791, dhidden weights: 66.7896662883911, doutput weights: 8.918209227865464\n",
      "dInput weights: 46.6301678816244, dhidden weights: 67.01704155704238, doutput weights: 8.315381411896752\n",
      "dInput weights: 47.439182100234994, dhidden weights: 67.40063081654814, doutput weights: 7.481722251256916\n",
      "dInput weights: 44.47352258188265, dhidden weights: 62.54671343079131, doutput weights: 6.413639471354977\n",
      "dInput weights: 32.07728009776384, dhidden weights: 47.61280392617985, doutput weights: 9.8092222687689\n",
      "dInput weights: 35.9949728199149, dhidden weights: 51.481972988954524, doutput weights: 6.231446641784957\n",
      "dInput weights: 85.90944189121879, dhidden weights: 123.36762937051087, doutput weights: 15.392757682704007\n",
      "Epoch loss 50: 18.428689270895642\n",
      "dInput weights: 40.90337779543431, dhidden weights: 63.32038167575749, doutput weights: 14.869893498309278\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "rec1 = RecurrentLayer(3, 4, 1)\n",
    "\n",
    "lr = 1e-3\n",
    "seq_len = 7\n",
    "\n",
    "for i in range(51):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for j in range(len(X_train) - seq_len):\n",
    "\n",
    "        rec1.forward(X_train[j:j+seq_len, :])\n",
    "\n",
    "        epoch_loss += mse_loss(rec1.output, y_train[j:j+seq_len])\n",
    "\n",
    "        loss_grad = mse_grad(rec1.output.reshape(-1), y_train[j:j+seq_len])\n",
    "\n",
    "        rec1.backward(loss_grad)\n",
    "\n",
    "        update_recurrent_layer(rec1, lr, momentum=0.)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch loss {i}: {epoch_loss / len(X_train)}')\n",
    "\n",
    "    print(f'dInput weights: {np.linalg.norm(rec1.dinput_weights)}, dhidden weights: {np.linalg.norm(rec1.dhidden_weights)}, doutput weights: {np.linalg.norm(rec1.doutput_weights)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.13724776 65.35577346 63.90170849]\n",
      "[69. 65. 64.]\n",
      "Loss: 0.7840106602377063\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "start = randint(0, len(X_test))\n",
    "seq_len = 3\n",
    "rec1.forward(X_test[start:start+seq_len, :])\n",
    "print(rec1.output.reshape(-1))\n",
    "print(y_test.reshape(-1)[start:start+seq_len])\n",
    "print(f'Loss: {mse_loss(rec1.output.reshape(-1), y_test.reshape(-1)[start:start+seq_len])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
