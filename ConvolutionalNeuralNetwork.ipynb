{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d(matrix, kernel, type='valid'):\n",
    "    \"\"\"\n",
    "    isto kao cross_correlate, samo se kernel rotira 180\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Flip the kernel for convolution\n",
    "        kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        kernel_flipped = np.rot90(kernel, 2)\n",
    "\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "        return output\n",
    "\n",
    "def cross_correlate2d(matrix, kernel, type='valid'): \n",
    "    \"\"\"\n",
    "    OVO RADI\n",
    "\n",
    "    dimenzija rezultata = dim_input - dim_kernel + 1\n",
    "    Y = I - K + 1\n",
    "\n",
    "    slidea kernel po regijama matrice velicine kernela, mnoze se elementi i zbrajaju\n",
    "\n",
    "    valid - krece se u granicama matrice, od ruba do ruba, dimenzija je Y = I - K + 1\n",
    "\n",
    "    full - izlazi van granica matrice, treba paddati matricu s nulama, Y = I + K - 1\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "# dilation = stride - 1\n",
    "# padding = kernel_size - 1\n",
    "def dilate(matrix, stride):\n",
    "    # Create a new matrix with appropriate size for dilation\n",
    "    dilated_shape = (matrix.shape[0] - 1) * stride + 1, (matrix.shape[1] - 1) * stride + 1\n",
    "    dilated = np.zeros(dilated_shape)\n",
    "    \n",
    "    # Place the original matrix elements into the dilated matrix\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            dilated[i * stride, j * stride] = matrix[i, j]\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "def pad_to_shape(matrix, target_shape):\n",
    "    # Calculate padding needed\n",
    "    pad_height = target_shape[0] - matrix.shape[0]\n",
    "    pad_width = target_shape[1] - matrix.shape[1]\n",
    "    \n",
    "    if pad_height < 0 or pad_width < 0:\n",
    "        raise ValueError(\"Target shape must be larger than the matrix shape.\")\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded = np.pad(matrix, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8. 7.]\n",
      " [4. 5.]]\n",
      "[[8 7]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -6. -2.]\n",
      " [ 2.  8.  7.  1.]\n",
      " [10.  4.  5. -3.]\n",
      " [14.  7.  8.  4.]]\n",
      "[[ 0 -1 -6 -2]\n",
      " [ 2  8  7  1]\n",
      " [10  4  5 -3]\n",
      " [14  7  8  4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  5.]\n",
      " [11.  3.]]\n",
      "[[ 7  5]\n",
      " [11  3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  8. 14.  4.]\n",
      " [ 4.  7.  5.  2.]\n",
      " [ 2. 11.  3.  8.]\n",
      " [-7.  0. -4.  0.]]\n",
      "[[ 1  8 14  4]\n",
      " [ 4  7  5  2]\n",
      " [ 2 11  3  8]\n",
      " [-7  0 -4  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_depth: int, kernel_size: int, stride: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (depth, height, width).\n",
    "\n",
    "        output_depth : int\n",
    "            Depth of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, a square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "        \"\"\"\n",
    "        # Unpack the input_shape tuple\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.output_depth = output_depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        #self.output_shape = (output_depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        output_height = int(np.floor((input_height - kernel_size) / stride) + 1) \n",
    "        output_width = int(np.floor((input_width - kernel_size) / stride) + 1)\n",
    "        self.output_shape = (output_depth, output_height, output_width)\n",
    "        self.kernels_shape = (output_depth, input_depth, kernel_size, kernel_size)\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_depth, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "        self.output += self.biases\n",
    "\n",
    "        for i in range(self.output_depth):\n",
    "            for j in range(self.input_depth):\n",
    "                for k in range(n_samples):\n",
    "                    self.output[k, i] += signal.correlate2d(self.inputs[k, j], self.kernels[i, j], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        #print(delta.shape)\n",
    "\n",
    "        for i in range(self.output_depth):\n",
    "            for j in range(self.input_depth):\n",
    "                for k in range(n_samples):\n",
    "\n",
    "                    self.dbiases[i] += delta[k, j]\n",
    "\n",
    "                    if self.stride == 1:\n",
    "\n",
    "                        self.dkernels[i, j] += signal.correlate2d(self.inputs[k, j], delta[k, j], \"valid\")\n",
    "                        self.dinputs[k, j] += signal.convolve2d(delta[k, j], self.kernels[i, j], \"full\")\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        delta_dilated = dilate(delta[k, j], stride=self.stride)\n",
    "\n",
    "                        dinput = signal.convolve2d(delta_dilated, self.kernels[i, j], \"full\")\n",
    "                        \n",
    "                        #print(f'input: {self.inputs[k, j].shape}, delta: {delta[k, j].shape} delta_dilated: {delta_dilated.shape}, dkernel shape: {dkernel.shape}')\n",
    "\n",
    "                        if dinput.shape == self.dinputs[k, j].shape:\n",
    "                            self.dinputs[k, j] += dinput\n",
    "                        else:\n",
    "                            dinput_padded = pad_to_shape(dinput, self.dinputs[k, j].shape)\n",
    "                            self.dinputs[k, j] += dinput_padded\n",
    "\n",
    "\n",
    "                        #print(delta_dilated.shape[0], self.inputs[k, j].shape[0], self.dkernels[i, j].shape[0])\n",
    "\n",
    "                        if delta_dilated.shape[0] == self.inputs[k, j].shape[0] - self.dkernels[i, j].shape[0] + 1:\n",
    "                            dkernel = signal.correlate2d(self.inputs[k, j], delta_dilated, \"valid\")\n",
    "                            self.dkernels[i, j] += dkernel\n",
    "                        else:\n",
    "                            new_shape = (self.inputs[k, j].shape[0] - self.dkernels[i, j].shape[0] + 1, self.inputs[k, j].shape[0] - self.dkernels[i, j].shape[0] + 1)\n",
    "                            delta_dilated_padded = pad_to_shape(delta_dilated, new_shape)\n",
    "                            dkernel = signal.correlate2d(self.inputs[k, j], delta_dilated_padded, \"valid\")\n",
    "                            self.dkernels[i, j] += dkernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts [batch_size, depth, height, width] to [batch_size, depth * height * width]\n",
    "        batch_size = inputs.shape[0]\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts [batch_size, depth * height * width] to [batch_size, depth, height, width]\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200,128) and (845,100) not aligned: 128 (dim 1) != 845 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[489], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     10\u001b[0m           Sigmoid(),\n\u001b[1;32m     11\u001b[0m           ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m13\u001b[39m), output_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     16\u001b[0m           Sigmoid()]\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mBCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(\u001b[38;5;241m5e-4\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:117\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mTrain the model.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_every:\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:47\u001b[0m, in \u001b[0;36mModel._forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Forward data through all the layers\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Output of the model is the output of the last layer\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/layers.py:49\u001b[0m, in \u001b[0;36mDenseLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Output is the dot product of the input matrix and weights plus biases\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200,128) and (845,100) not aligned: 128 (dim 1) != 845 (dim 0)"
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "# 26, 13, 9, 7\n",
    "# output = floor( (input - kernel) / stride ) + 1\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_depth=5, kernel_size=3, stride=2),\n",
    "          Sigmoid(),\n",
    "          ConvolutionalLayer(input_shape=(5, 13, 13), output_depth=8, kernel_size=4, stride=3),\n",
    "          ReshapeLayer(input_shape=(8, 4, 4), output_shape=8*4*4),\n",
    "          DenseLayer(8*4*4, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-4))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "i, j = 0, 0\n",
    "\n",
    "for idx, x in enumerate(x_test[:4]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 2 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_depth):\n",
    "    for j in range(conv.input_depth):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n",
      "(1000, 10)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:1000])\n",
    "x_test = preprocess_whole_mnist(x_test[:1000])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:1000])\n",
    "y_test = one_hot_encode(y_test[:1000])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 2380.5222627907783 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[479], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      2\u001b[0m           Sigmoid(),\n\u001b[1;32m      3\u001b[0m           ReshapeLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m26\u001b[39m), output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m26\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m26\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      7\u001b[0m           Softmax()]\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mCCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-2\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:124\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m===== EPOCH : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===== LOSS : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function\u001b[38;5;241m.\u001b[39mcalculate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput,\u001b[38;5;250m \u001b[39my)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_parameters()\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:72\u001b[0m, in \u001b[0;36mModel._backward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Pass gradients backwards to all layers\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))):\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdinputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[470], line 94\u001b[0m, in \u001b[0;36mConvolutionalLayer.backward\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdkernels[i, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mcorrelate2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[k, j], delta[k, j], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs[k, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     delta_dilated \u001b[38;5;241m=\u001b[39m dilate(delta[k, j], stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride)\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/scipy/signal/_signaltools.py:1740\u001b[0m, in \u001b[0;36mconvolve2d\u001b[0;34m(in1, in2, mode, boundary, fillvalue)\u001b[0m\n\u001b[1;32m   1738\u001b[0m val \u001b[38;5;241m=\u001b[39m _valfrommode(mode)\n\u001b[1;32m   1739\u001b[0m bval \u001b[38;5;241m=\u001b[39m _bvalfromboundary(boundary)\n\u001b[0;32m-> 1740\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_sigtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_depth=5, kernel_size=3),\n",
    "          Sigmoid(),\n",
    "          ReshapeLayer(input_shape=(5, 26, 26), output_shape=5 * 26 * 26),\n",
    "          DenseLayer(5 * 26 * 26, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Softmax()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=3e-2))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "i, j = 0, 0\n",
    "\n",
    "for idx, x in enumerate(x_test[:4]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred)}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 2 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
