{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "- operation from the field of signal processing\n",
    "\n",
    "- a kernel matrix is slid over the input matrix, doing element-wise multiplication and summing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](img/convolution.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d(matrix, kernel, type='valid'):\n",
    "    \"\"\"\n",
    "    isto kao cross_correlate, samo se kernel rotira 180\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Flip the kernel for convolution\n",
    "        kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        kernel_flipped = np.rot90(kernel, 2)\n",
    "\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "        return output\n",
    "\n",
    "def cross_correlate2d(matrix, kernel, type='valid'): \n",
    "    \"\"\"\n",
    "    OVO RADI\n",
    "\n",
    "    dimenzija rezultata = dim_input - dim_kernel + 1\n",
    "    Y = I - K + 1\n",
    "\n",
    "    slidea kernel po regijama matrice velicine kernela, mnoze se elementi i zbrajaju\n",
    "\n",
    "    valid - krece se u granicama matrice, od ruba do ruba, dimenzija je Y = I - K + 1\n",
    "\n",
    "    full - izlazi van granica matrice, treba paddati matricu s nulama, Y = I + K - 1\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "def dilate(arr: np.ndarray, stride: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expands boundaries of an array by adding rows and columns of zeros between array elements.\n",
    "    Number of rows and columns between two elements is stride - 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to dilate.\n",
    "\n",
    "    stride : int\n",
    "        Number of zeroes added between a pair of elements.\n",
    "        NOTE: stride - 1 zeros are added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dilated_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Create a new array with appropriate size for dilation\n",
    "    dilated_shape = (arr.shape[0] - 1) * stride + 1, (arr.shape[1] - 1) * stride + 1\n",
    "    dilated = np.zeros(dilated_shape)\n",
    "    \n",
    "    # Place the original array elements into the dilated array\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            dilated[i * stride, j * stride] = arr[i, j]\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "def pad_to_shape(arr: np.ndarray, target_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds padding to array so it matches target shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to pad.\n",
    "\n",
    "    target_shape : tuple\n",
    "        Shape of the array after padding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padded_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Calculate padding needed\n",
    "    pad_height = target_shape[0] - arr.shape[0]\n",
    "    pad_width = target_shape[1] - arr.shape[1]\n",
    "    \n",
    "    if pad_height < 0 or pad_width < 0:\n",
    "        raise ValueError(\"Target shape must be larger than the array shape.\")\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8. 7.]\n",
      " [4. 5.]]\n",
      "[[8 7]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -6. -2.]\n",
      " [ 2.  8.  7.  1.]\n",
      " [10.  4.  5. -3.]\n",
      " [14.  7.  8.  4.]]\n",
      "[[ 0 -1 -6 -2]\n",
      " [ 2  8  7  1]\n",
      " [10  4  5 -3]\n",
      " [14  7  8  4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  5.]\n",
      " [11.  3.]]\n",
      "[[ 7  5]\n",
      " [11  3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  8. 14.  4.]\n",
      " [ 4.  7.  5.  2.]\n",
      " [ 2. 11.  3.  8.]\n",
      " [-7.  0. -4.  0.]]\n",
      "[[ 1  8 14  4]\n",
      " [ 4  7  5  2]\n",
      " [ 2 11  3  8]\n",
      " [-7  0 -4  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_channels: int, kernel_size: int, stride: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (channels, height, width).\n",
    "\n",
    "        output_channels : int\n",
    "            Depth of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, a square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "        \"\"\"\n",
    "        # Unpack the input_shape tuple\n",
    "        input_channels, input_height, input_width = input_shape\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Calculate output height and width\n",
    "        output_height = int(floor((input_height - kernel_size) / stride) + 1) \n",
    "        output_width = int(floor((input_width - kernel_size) / stride) + 1)\n",
    "\n",
    "        # Create output and kernel shapes\n",
    "        self.output_shape = (output_channels, output_height, output_width)\n",
    "        self.kernels_shape = (output_channels, input_channels, kernel_size, kernel_size)\n",
    "\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Store inputs for later use\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_channels, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Add bias to output\n",
    "        self.output += self.biases\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "                    # Output is the cross correlation in valid mode between the input and kernel\n",
    "                    self.output[i, j] += signal.correlate2d(self.inputs[i, k], self.kernels[j, k], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Initialize gradient attributes\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Gradient with respect to biases is the sum of deltas\n",
    "            self.dbiases += delta[i]\n",
    "\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "\n",
    "                    if self.stride == 1:\n",
    "                        # Gradient with respect to kernels is the valid correlaton between input and delta\n",
    "                        self.dkernels[j, k] += signal.correlate2d(self.inputs[i, k], delta[i, j], \"valid\")\n",
    "                        # Gradient with respect to inputs is the full convolution between delta and kernel\n",
    "                        self.dinputs[i, k] += signal.convolve2d(delta[i, j], self.kernels[j, k], \"full\")\n",
    "\n",
    "                    # If stride is bigger than 1, dilation of delta is required\n",
    "                    else:\n",
    "\n",
    "                        delta_dilated = dilate(delta[i, j], stride=self.stride)\n",
    "\n",
    "                        delta_dilated_shape = delta_dilated.shape\n",
    "                        input_shape = self.inputs[i, k].shape[0]\n",
    "                        kernel_shape = self.dkernels[j, k].shape[0]\n",
    "\n",
    "                        if delta_dilated_shape == input_shape - kernel_shape + 1:\n",
    "                            # If dilated delta shape matches the needed correlation shape gradient is computed\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated, \"valid\")\n",
    "                        else:\n",
    "                            # If dilated delta shape doesn't match the needed correlation shape padding is needed\n",
    "                            new_delta_shape = (input_shape - kernel_shape + 1, input_shape - kernel_shape + 1)\n",
    "                            delta_dilated_padded = pad_to_shape(delta_dilated, new_delta_shape)\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated_padded, \"valid\")\n",
    "                            \n",
    "                        self.dkernels[j, k] += dkernel\n",
    "\n",
    "                        # Full convolution between dilated delta and kernel similar to stride=1\n",
    "                        dinput = signal.convolve2d(delta_dilated, self.kernels[j, k], \"full\")\n",
    "\n",
    "                        if dinput.shape == self.dinputs[i, k].shape:\n",
    "                            # If the shape of convolution result is equal to input gradient shape they can be summed\n",
    "                            self.dinputs[i, k] += dinput\n",
    "                        else:\n",
    "                            # If the shapes are not equal, padding of result is needed to match the input gradient shape\n",
    "                            dinput_padded = pad_to_shape(dinput, self.dinputs[i, k].shape)\n",
    "                            self.dinputs[i, k] += dinput_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts [batch_size, depth, height, width] to [batch_size, depth * height * width]\n",
    "        batch_size = inputs.shape[0]\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts [batch_size, depth * height * width] to [batch_size, depth, height, width]\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 0.6740765563038471 =====\n",
      "===== EPOCH : 20 ===== LOSS : 0.4920325467826159 =====\n",
      "===== EPOCH : 40 ===== LOSS : 0.08252406995591098 =====\n",
      "===== EPOCH : 60 ===== LOSS : 0.04781801159667813 =====\n",
      "===== EPOCH : 80 ===== LOSS : 0.03285776239104376 =====\n",
      "===== EPOCH : 100 ===== LOSS : 0.02467342863099139 =====\n"
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "# output = floor( (input - kernel) / stride ) + 1\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=5, kernel_size=3),\n",
    "          Sigmoid(),\n",
    "          ConvolutionalLayer(input_shape=(5, 26, 26), output_channels=8, kernel_size=4, stride=2),\n",
    "          ReshapeLayer(input_shape=(8, 12, 12), output_shape=8*12*12),\n",
    "          DenseLayer(8*12*12, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-4))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0, 0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_channels):\n",
    "    for j in range(conv.input_channels):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28)\n",
      "(500, 1, 28, 28)\n",
      "(1000, 10)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:1000])\n",
    "x_test = preprocess_whole_mnist(x_test[:500])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:1000])\n",
    "y_test = one_hot_encode(y_test[:500])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 2457.9189665015124 =====\n",
      "===== EPOCH : 10 ===== LOSS : 2204.4628855131496 =====\n",
      "===== EPOCH : 20 ===== LOSS : 2152.9036795378497 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m      2\u001b[0m           Sigmoid(),\n\u001b[0;32m      3\u001b[0m           ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m26\u001b[39m), output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m      8\u001b[0m           Softmax()]\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mCCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Grgo\\Faks\\Python\\DLFS\\dlfs\\model.py:117\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03mTrain the model.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_every:\n",
      "File \u001b[1;32md:\\Grgo\\Faks\\Python\\DLFS\\dlfs\\model.py:47\u001b[0m, in \u001b[0;36mModel._forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Forward data through all the layers\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Output of the model is the output of the last layer\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "Cell \u001b[1;32mIn[7], line 74\u001b[0m, in \u001b[0;36mConvolutionalLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_channels):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;66;03m# Output is the cross correlation in valid mode between the input and kernel\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mcorrelate2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[i, k], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels[j, k], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)[::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, ::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=5, kernel_size=3),\n",
    "          Sigmoid(),\n",
    "          ConvolutionalLayer(input_shape=(5, 26, 26), output_channels=8, kernel_size=4, stride=2),\n",
    "          ReshapeLayer(input_shape=(8, 12, 12), output_shape=8*12*12),\n",
    "          DenseLayer(8*12*12, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Softmax()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=5e-2))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred[0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
