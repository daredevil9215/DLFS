{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d(matrix, kernel, type='valid'):\n",
    "    \"\"\"\n",
    "    isto kao cross_correlate, samo se kernel rotira 180\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Flip the kernel for convolution\n",
    "        kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        kernel_flipped = np.rot90(kernel, 2)\n",
    "\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "        return output\n",
    "\n",
    "def cross_correlate2d(matrix, kernel, type='valid'): \n",
    "    \"\"\"\n",
    "    OVO RADI\n",
    "\n",
    "    dimenzija rezultata = dim_input - dim_kernel + 1\n",
    "    Y = I - K + 1\n",
    "\n",
    "    slidea kernel po regijama matrice velicine kernela, mnoze se elementi i zbrajaju\n",
    "\n",
    "    valid - krece se u granicama matrice, od ruba do ruba, dimenzija je Y = I - K + 1\n",
    "\n",
    "    full - izlazi van granica matrice, treba paddati matricu s nulama, Y = I + K - 1\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if type == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif type == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8. 7.]\n",
      " [4. 5.]]\n",
      "[[8 7]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlate full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -6. -2.]\n",
      " [ 2.  8.  7.  1.]\n",
      " [10.  4.  5. -3.]\n",
      " [14.  7.  8.  4.]]\n",
      "[[ 0 -1 -6 -2]\n",
      " [ 2  8  7  1]\n",
      " [10  4  5 -3]\n",
      " [14  7  8  4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = cross_correlate2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.correlate2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  5.]\n",
      " [11.  3.]]\n",
      "[[ 7  5]\n",
      " [11  3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel)\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel, mode='valid')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  8. 14.  4.]\n",
      " [ 4.  7.  5.  2.]\n",
      " [ 2. 11.  3.  8.]\n",
      " [-7.  0. -4.  0.]]\n",
      "[[ 1  8 14  4]\n",
      " [ 4  7  5  2]\n",
      " [ 2 11  3  8]\n",
      " [-7  0 -4  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 6, 2],\n",
    "              [5, 3, 1],\n",
    "              [7, 0 ,4]])\n",
    "\n",
    "kernel = np.array([[1, 2],\n",
    "                   [-1, 0]])\n",
    "\n",
    "c = convolve2d(a, kernel, type='full')\n",
    "print(c)\n",
    "\n",
    "c = signal.convolve2d(a, kernel)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_depth: int, kernel_size: int, stride: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (depth, height, width).\n",
    "\n",
    "        output_depth : int\n",
    "            Depth of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, a square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "        \"\"\"\n",
    "        # Unpack the input_shape tuple\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.output_depth = output_depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        #self.output_shape = (output_depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        output_height = int(np.floor((input_height - kernel_size) / stride) + 1) \n",
    "        output_width = int(np.floor((input_width - kernel_size) / stride) + 1)\n",
    "        self.output_shape = (output_depth, output_height, output_width)\n",
    "        self.kernels_shape = (output_depth, input_depth, kernel_size, kernel_size)\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_depth, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "        self.output += self.biases\n",
    "\n",
    "        for i in range(self.output_depth):\n",
    "            for j in range(self.input_depth):\n",
    "                for k in range(n_samples):\n",
    "                    self.output[k, i] += signal.correlate2d(self.inputs[k, j], self.kernels[i, j], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        for i in range(self.output_depth):\n",
    "            for j in range(self.input_depth):\n",
    "                for k in range(n_samples):\n",
    "\n",
    "                    self.dbiases[i] += delta[k, j]\n",
    "\n",
    "                    if self.stride == 1:\n",
    "                        self.dkernels[i, j] += signal.correlate2d(self.inputs[k, j], delta[k, j], \"valid\")\n",
    "                        self.dinputs[k, j] += signal.convolve2d(delta[k, j], self.kernels[i, j], \"full\")\n",
    "                    else:\n",
    "                        dinputs_stride = signal.convolve2d(delta[k, j], self.kernels[i, j], \"full\")\n",
    "                        #dkernels_stride = signal.correlate2d(self.inputs[k, j], delta[k, j], \"valid\")[::self.stride, ::self.stride]\n",
    "\n",
    "                        for y in range(0, self.output_shape[1], self.stride):\n",
    "                            for x in range(0, self.output_shape[2], self.stride):\n",
    "                                self.dinputs[k, j, y // self.stride, x // self.stride] += dinputs_stride[y, x]\n",
    "                                self.dkernels[i, j] += self.inputs[k, j, y:y+self.kernel_size, x:x+self.kernel_size] * delta[k, i, y, x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts [batch_size, depth, height, width] to [batch_size, depth * height * width]\n",
    "        batch_size = inputs.shape[0]\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts [batch_size, depth * height * width] to [batch_size, depth, height, width]\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 0.6993317267087176 =====\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (28,28) (4,4) (28,28) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[541], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     10\u001b[0m           Sigmoid(),\n\u001b[1;32m     11\u001b[0m           ReshapeLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m9\u001b[39m), output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m9\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m9\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m           Sigmoid()]\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mBCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(\u001b[38;5;241m5e-4\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:124\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m===== EPOCH : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===== LOSS : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function\u001b[38;5;241m.\u001b[39mcalculate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput,\u001b[38;5;250m \u001b[39my)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_parameters()\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:72\u001b[0m, in \u001b[0;36mModel._backward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Pass gradients backwards to all layers\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))):\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdinputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[538], line 95\u001b[0m, in \u001b[0;36mConvolutionalLayer.backward\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m     93\u001b[0m dinputs_stride \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mconvolve2d(delta[k, i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels[i, j], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#dkernels_stride = signal.correlate2d(self.inputs[k, j], delta[k, j], \"valid\")[::self.stride, ::self.stride]\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs[k, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dinputs_stride[::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, ::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m#self.dinputs[k, j, y, x] += dinputs_stride[y, x]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (28,28) (4,4) (28,28) "
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "# 26, 13, 9, 7\n",
    "# output = floor( (input - kernel) / stride ) + 1\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_depth=5, kernel_size=3, stride=3),\n",
    "          Sigmoid(),\n",
    "          ReshapeLayer(input_shape=(5, 9, 9), output_shape=5*9*9),\n",
    "          DenseLayer(5 * 9 * 9, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-4))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "i, j = 0, 0\n",
    "\n",
    "for idx, x in enumerate(x_test[:4]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 2 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_depth):\n",
    "    for j in range(conv.input_depth):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n",
      "(1000, 10)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:1000])\n",
    "x_test = preprocess_whole_mnist(x_test[:1000])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:1000])\n",
    "y_test = one_hot_encode(y_test[:1000])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 2550.510128098321 =====\n",
      "===== EPOCH : 10 ===== LOSS : 2315.241271033432 =====\n",
      "===== EPOCH : 20 ===== LOSS : 2288.612126102572 =====\n",
      "===== EPOCH : 30 ===== LOSS : 2272.6092355554024 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[521], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      2\u001b[0m           Sigmoid(),\n\u001b[1;32m      3\u001b[0m           ReshapeLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m26\u001b[39m), output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m26\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m26\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      7\u001b[0m           Softmax()]\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mCCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-2\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:117\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mTrain the model.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_every:\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/model.py:47\u001b[0m, in \u001b[0;36mModel._forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Forward data through all the layers\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Output of the model is the output of the last layer\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[0;32m~/Desktop/Programstvo/Python/Strojno/DLFS/dlfs/layers.py:49\u001b[0m, in \u001b[0;36mDenseLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Output is the dot product of the input matrix and weights plus biases\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_depth=5, kernel_size=3),\n",
    "          Sigmoid(),\n",
    "          ReshapeLayer(input_shape=(5, 26, 26), output_shape=5 * 26 * 26),\n",
    "          DenseLayer(5 * 26 * 26, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Softmax()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=3e-2))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "i, j = 0, 0\n",
    "\n",
    "for idx, x in enumerate(x_test[:4]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred)}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 2 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
