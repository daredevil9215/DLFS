{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "- operation from the field of digital signal processing\n",
    "\n",
    "- 2D convolution uses two matrices, input and kernel, to produce some output\n",
    "\n",
    "- a kernel matrix is slid over the input matrix, doing element-wise multiplication and summing\n",
    "\n",
    "- kernel can be thought of as a filter, and the result of the operation is a filtered image\n",
    "\n",
    "- depending on the kernel, there are many use cases: \n",
    "    - blurring\n",
    "    - smoothing\n",
    "    - edge detection\n",
    "    - sharpening\n",
    "    - feature detection\n",
    "    - noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ValidConvolution](img/conv_valid.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FullConvolution](img/conv_full.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid vs. full convolution\n",
    "\n",
    "- **valid**\n",
    "    - kernel is slid within borders of the input matrix\n",
    "    - kernel and input overlap completely\n",
    "    - output matrix is smaller in size compared to input matrix\n",
    "\n",
    "- **full**\n",
    "    - kernel is slid outside the borders of the input matrix\n",
    "    - kernel and input overlap partially at borders\n",
    "    - region outside of borders is padded with zeros\n",
    "    - output is larger in size compared to input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlation vs. Convolution\n",
    "\n",
    "- Cross Correlation is sliding a kernel over the input matrix (denoted using $\\star$ symbol)\n",
    "\n",
    "- Convolution is sliding a *180 degrees rotated* kernel over the input matrix (denoted using $\\ast$ symbol)\n",
    "\n",
    "- this subtle difference is observed in backpropagation of the convolutional layer\n",
    "\n",
    "- Cross Correlation is used primarily in equations and code throughout this notebook, but the same can be achieved with Convolution with minor changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "- step size of kernel when sliding over the input matrix\n",
    "\n",
    "- affects output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stride](img/conv_stride.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output size formula (for square matrices)\n",
    "\n",
    "- $ \\text{valid} = \\lfloor \\frac{\\text{input size} - \\text{kernel size}}{\\text{stride}} \\rfloor + 1$\n",
    "\n",
    "- $\\text{full} = \\lfloor \\frac{\\text{input size} + \\text{kernel size}}{\\text{stride}} \\rfloor - 1$\n",
    "\n",
    "- $\\lfloor \\rfloor$ denotes the floor function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation for convolutional layer\n",
    "\n",
    "- input matrix $X$\n",
    "\n",
    "- kernel matrix $k$\n",
    "\n",
    "- output matrix $Y$\n",
    "\n",
    "$$Y = X \\star_{\\text{valid}} k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward propagation for convolutional layer\n",
    "\n",
    "- accumulated gradient from other layers $\\delta$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to input matrix $\\frac{\\partial L}{\\partial X}$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to kernel $\\frac{\\partial L}{\\partial k}$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X} = \\delta \\ast_{\\text{full}} k \\quad \\quad \\frac{\\partial L}{\\partial k} = X \\star_{\\text{valid}} \\delta $$\n",
    "\n",
    "- if stride greater than 1 is present, $\\delta$ needs to be dilated and padded to match shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def convolve2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for convolving 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of convolution.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    # Flip the kernel for convolution\n",
    "    kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    if mode == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "    \n",
    "    elif mode == 'full':\n",
    "\n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        # Pad input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.   4.  -9. -12.]\n",
      " [  7.   6.  -5. -11.]\n",
      " [  9.   8.  -6.  -7.]\n",
      " [  7.   4.  -8.  -7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='valid')\n",
    "# It is noticable that the rotation of kernel from convolution does not yield the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.  -1.   3.  -1.  -5.  -4.   5.   6.]\n",
      " [ -7.  -3.   6.   0.  -8. -10.   9.  13.]\n",
      " [-12.  -7.  11.   4.  -9. -12.  10.  15.]\n",
      " [-10.  -8.   7.   6.  -5. -11.   8.  13.]\n",
      " [-12.  -9.   9.   8.  -6.  -7.   9.   8.]\n",
      " [-10.  -6.   7.   4.  -8.  -7.  11.   9.]\n",
      " [ -9.  -4.   8.   3.  -7.  -4.   8.   5.]\n",
      " [ -3.  -1.   3.   0.  -3.  -2.   3.   3.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='full')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross correlation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for cross correlating 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of cross correlation.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if mode == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif mode == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid cross correlation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.  -4.   9.  12.]\n",
      " [ -7.  -6.   5.  11.]\n",
      " [ -9.  -8.   6.   7.]\n",
      " [ -7.  -4.   8.   7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = cross_correlate2d(x, kernel, mode='valid')\n",
    "# Using cross correlation which does not rotate the kernel yields the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(arr: np.ndarray, stride: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expands boundaries of an array by adding rows and columns of zeros between array elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to dilate.\n",
    "\n",
    "    stride : int\n",
    "        Number of zeroes added between a pair of elements.\n",
    "        NOTE: stride - 1 zeros are added between elements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dilated_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Create a new array with appropriate size for dilation\n",
    "    dilated_shape = (arr.shape[0] - 1) * stride + 1, (arr.shape[1] - 1) * stride + 1\n",
    "    dilated = np.zeros(dilated_shape)\n",
    "    \n",
    "    # Place the original array elements into the dilated array\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            dilated[i * stride, j * stride] = arr[i, j]\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "def pad_to_shape(arr: np.ndarray, target_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds padding to array so it matches target shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to pad.\n",
    "\n",
    "    target_shape : tuple\n",
    "        Shape of the array after padding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padded_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Calculate padding needed\n",
    "    pad_height = target_shape[0] - arr.shape[0]\n",
    "    pad_width = target_shape[1] - arr.shape[1]\n",
    "    \n",
    "    if pad_height < 0 or pad_width < 0:\n",
    "        raise ValueError(\"Target shape must be larger than the array shape.\")\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilate and pad example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilated:\n",
      "[[1. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [3. 0. 4.]]\n",
      "Dilated and padded:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 4. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "dilated = dilate(x, 2)\n",
    "print(f'Dilated:\\n{dilated}')\n",
    "\n",
    "dilated_padded = pad_to_shape(dilated, (5, 5))\n",
    "print(f'Dilated and padded:\\n{dilated_padded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_channels: int, kernel_size: int, stride: int = 1, padding: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (channels, width, height).\n",
    "\n",
    "        output_channels : int\n",
    "            Number of channels of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "\n",
    "        padding : int, default=0\n",
    "            Amount of padding added to input.\n",
    "        \"\"\"\n",
    "        # Unpack input_shape tuple\n",
    "        input_channels, input_width, input_height = input_shape\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Calculate output width and height\n",
    "        output_width = int(floor((input_width - kernel_size + 2 * padding) / stride) + 1)\n",
    "        output_height = int(floor((input_height - kernel_size + + 2 * padding) / stride) + 1) \n",
    "\n",
    "        # Create output and kernel shapes\n",
    "        self.output_shape = (output_channels, output_width, output_height)\n",
    "        self.kernels_shape = (output_channels, input_channels, kernel_size, kernel_size)\n",
    "\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Store inputs for later use\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_channels, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Add bias to output\n",
    "        self.output += self.biases\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "                    # Output is the cross correlation in valid mode between the input and kernel\n",
    "                    if self.padding:\n",
    "                        inputs = np.pad(self.inputs[i, k], pad_width=self.padding, mode='constant')\n",
    "                    else:\n",
    "                        inputs = self.inputs[i, k].copy()\n",
    "                    self.output[i, j] += signal.correlate2d(inputs, self.kernels[j, k], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Initialize gradient attributes\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        \"\"\"if self.padding:\n",
    "            input_shape = list(self.inputs.shape)\n",
    "            input_shape[2] += 2 * self.padding\n",
    "            input_shape[3] += 2 * self.padding\"\"\"\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "\n",
    "        #print(f'u backwardu conv layera delta: {delta.shape}')\n",
    "        #print(f'u backwardu conv layera dinputs: {self.dinputs.shape}')\n",
    "\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Gradient with respect to biases is the sum of deltas\n",
    "            #print(f'biases: {self.biases.shape}, dbiases: {self.dbiases.shape}, delta: {delta[i].shape}')\n",
    "            self.dbiases += delta[i]\n",
    "\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "\n",
    "                    if self.stride == 1:\n",
    "                        # Gradient with respect to kernels is the valid correlaton between input and delta\n",
    "                        if self.padding != 0:\n",
    "                            inputs = np.pad(self.inputs[i, k], pad_width=self.padding)\n",
    "                            self.dkernels[j, k] += signal.correlate2d(inputs, delta[i, j], \"valid\")\n",
    "                            dinputs = signal.convolve2d(delta[i, j], self.kernels[j, k], \"full\")\n",
    "                            self.dinputs[i, k] += dinputs[self.padding:-self.padding, self.padding:-self.padding]\n",
    "                        else:\n",
    "                            self.dkernels[j, k] += signal.correlate2d(self.inputs[i, k], delta[i, j], \"valid\")\n",
    "                            # Gradient with respect to inputs is the full convolution between delta and kernel\n",
    "                            self.dinputs[i, k] += signal.convolve2d(delta[i, j], self.kernels[j, k], \"full\")\n",
    "\n",
    "                    # If stride is bigger than 1, dilation of delta is required\n",
    "                    else:\n",
    "\n",
    "                        delta_dilated = dilate(delta[i, j], stride=self.stride)\n",
    "\n",
    "                        delta_dilated_shape = delta_dilated.shape\n",
    "                        input_shape = self.inputs[i, k].shape[0]\n",
    "                        kernel_shape = self.dkernels[j, k].shape[0]\n",
    "\n",
    "                        if self.padding != 0:\n",
    "                            inputs = np.pad(self.inputs[i, k], pad_width=self.padding)\n",
    "\n",
    "                        #print(f'u backwardu conv layera delta_dilated: {delta_dilated_shape}')\n",
    "\n",
    "                        if delta_dilated_shape == input_shape - kernel_shape + 2*self.padding + 1:\n",
    "                            # If dilated delta shape matches the needed correlation shape gradient is computed\n",
    "                            dkernel = signal.correlate2d(inputs, delta_dilated, \"valid\")\n",
    "                        else:\n",
    "                            # If dilated delta shape doesn't match the needed correlation shape padding is needed\n",
    "                            new_delta_shape = (input_shape - kernel_shape + 2*self.padding + 1, input_shape - kernel_shape + 2*self.padding + 1)\n",
    "                            delta_dilated = pad_to_shape(delta_dilated, new_delta_shape)\n",
    "                            #print(f'u backwardu conv layera delta_dilated_padded: {delta_dilated.shape}')\n",
    "                            #print(f'u backwardu conv layera input: {inputs.shape}')\n",
    "                            dkernel = signal.correlate2d(inputs, delta_dilated, \"valid\")\n",
    "                            \n",
    "                        self.dkernels[j, k] += dkernel\n",
    "\n",
    "                        # Full convolution between dilated delta and kernel similar to stride=1\n",
    "                        dinput = signal.convolve2d(delta_dilated, self.kernels[j, k], \"full\")\n",
    "                        #print(f'u backwardu conv layera dinput nakon convolve: {dinput.shape}')\n",
    "\n",
    "                        if dinput.shape == self.dinputs[i, k].shape:\n",
    "                            # If the shape of convolution result is equal to input gradient shape they can be summed\n",
    "                            self.dinputs[i, k] += dinput\n",
    "                        else:\n",
    "                            # If the shapes are not equal, padding of result is needed to match the input gradient shape\n",
    "                            if self.padding == 0:\n",
    "                                dinput_padded = pad_to_shape(dinput, self.dinputs[i, k].shape)\n",
    "                                self.dinputs[i, k] += dinput_padded\n",
    "                            else:\n",
    "                                dinput_depadded = dinput[self.padding:-self.padding, self.padding:-self.padding]\n",
    "                                self.dinputs[i, k] += dinput_depadded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts (batch_size, channels, width, height) to (batch_size, channels * width * height)\n",
    "        batch_size = inputs.shape[0]\n",
    "        #print(f'input: {inputs.shape}')\n",
    "        #print(f'output: {self.output_shape}')\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts (batch_size, channels * width * height) to (batch_size, channels, width, height)\n",
    "        #print(f'u backwardu reshape layera delta: {delta.shape}')\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))\n",
    "        #print(f'u backwardu reshape layera dinputs: {self.dinputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, stride: int = 1, padding: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (channels, width, height).\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a kernel, square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "\n",
    "        padding : int, default=0\n",
    "            Amount of padding added to input.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack the input_shape tuple\n",
    "        input_channels, input_width, input_height = input_shape\n",
    "\n",
    "        # Store input channels, kernel size and stride\n",
    "        self.input_channels = input_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Calculate output width and height\n",
    "        self.output_width = int(floor((input_width - kernel_size + 2 * padding) / stride) + 1)\n",
    "        self.output_height = int(floor((input_height - kernel_size + 2 * padding) / stride) + 1) \n",
    "\n",
    "        # Create output shape\n",
    "        self.output_shape = (self.input_channels, self.output_height, self.output_width)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # List for storing indices of max elements\n",
    "        self.max_indices = []\n",
    "        \n",
    "        # Store inputs\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Number of samples, first dimenison\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, input_channels, width, height)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Loop through every sample\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Add empty list to max indices for the current sample\n",
    "            self.max_indices.append([])\n",
    "\n",
    "            # Loop through every channel\n",
    "            for j in range(self.input_channels):\n",
    "\n",
    "                # Add empty list to max indices for the current channel of the current sample\n",
    "                self.max_indices[i].append([])\n",
    "\n",
    "                # Loop through each element of the output\n",
    "                for k in range(self.output_width):\n",
    "                    for l in range(self.output_height):\n",
    "                        \n",
    "                        # Initalize axis 0 start and end indices \n",
    "                        axis_0_start = k * self.stride\n",
    "                        axis_0_end = axis_0_start + self.kernel_size\n",
    "\n",
    "                        # Initalize axis 1 start and end indices\n",
    "                        axis_1_start = l*self.stride\n",
    "                        axis_1_end = axis_1_start + self.kernel_size\n",
    "\n",
    "                        if self.padding:\n",
    "                            arr = np.pad(self.inputs[i, j], pad_width=self.padding, mode='constant')\n",
    "                        else:\n",
    "                            arr = self.inputs[i, j].copy()\n",
    "                            \n",
    "                        # Use axis 0 and 1 indices to obtain max pooling region   \n",
    "                        region = arr[axis_0_start:axis_0_end, axis_1_start:axis_1_end]\n",
    "\n",
    "                        # Get the max element from the region, save it to output\n",
    "                        self.output[i, j, k, l] = np.max(region)\n",
    "                        \n",
    "                        # Get the index of the max element within the region (region is flattened array in this case)\n",
    "                        max_index = np.argmax(region)\n",
    "\n",
    "                        # Calculate the position of the max element within the sample\n",
    "                        max_element_position = (axis_0_start + (max_index // self.kernel_size), axis_1_start + (max_index % self.kernel_size))\n",
    "\n",
    "                        # Store the position of max element\n",
    "                        self.max_indices[i][j].append(max_element_position)\n",
    "\n",
    "        #print(f'output maxpool: {self.output.shape}')\n",
    "\n",
    "    def backward(self, delta):\n",
    "\n",
    "        #print(f'u backwardu maxpool layera delta: {delta.shape}')\n",
    "\n",
    "        # Initialize input gradient\n",
    "        \"\"\"if self.padding:\n",
    "            input_shape = list(self.inputs.shape)\n",
    "            input_shape[2] += 2 * self.padding\n",
    "            input_shape[3] += 2 * self.padding\n",
    "            input_shape = tuple(input_shape)\n",
    "        else:\"\"\"\n",
    "        input_shape = self.inputs.shape\n",
    "        \n",
    "        self.dinputs = np.zeros(input_shape)\n",
    "\n",
    "        # Number of samples, first dimenison\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through samples\n",
    "        for i in range(n_samples):\n",
    "            # Loop through channels\n",
    "            for j in range(self.input_channels):\n",
    "                # Loop through pairs of indices zipped with a delta value\n",
    "                for (k, l), d in zip(self.max_indices[i][j], delta[i, j].flatten()):\n",
    "                    dinput = np.zeros((input_shape[2] + 2 * self.padding, input_shape[3] + 2 * self.padding))\n",
    "                    dinput[k, l] = d\n",
    "\n",
    "                if self.padding:\n",
    "                    self.dinputs[i, j] = dinput[self.padding:-self.padding, self.padding:-self.padding]\n",
    "                \n",
    "\n",
    "        #print(f'u backwardu maxpool layera dinput: {self.dinputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 0.6955441904138067 =====\n",
      "===== EPOCH : 1 ===== LOSS : 0.6810532111971207 =====\n",
      "===== EPOCH : 2 ===== LOSS : 0.6711718415051132 =====\n",
      "===== EPOCH : 3 ===== LOSS : 0.6628438036977999 =====\n",
      "===== EPOCH : 4 ===== LOSS : 0.65510883723169 =====\n",
      "===== EPOCH : 5 ===== LOSS : 0.647579061761231 =====\n",
      "===== EPOCH : 6 ===== LOSS : 0.6401252343895737 =====\n",
      "===== EPOCH : 7 ===== LOSS : 0.6327082235790369 =====\n",
      "===== EPOCH : 8 ===== LOSS : 0.6253370492071197 =====\n",
      "===== EPOCH : 9 ===== LOSS : 0.6180255356642494 =====\n",
      "===== EPOCH : 10 ===== LOSS : 0.6107747359059545 =====\n",
      "===== EPOCH : 11 ===== LOSS : 0.6035684396691957 =====\n",
      "===== EPOCH : 12 ===== LOSS : 0.5963841817510271 =====\n",
      "===== EPOCH : 13 ===== LOSS : 0.5892033680665848 =====\n",
      "===== EPOCH : 14 ===== LOSS : 0.5820166342701587 =====\n",
      "===== EPOCH : 15 ===== LOSS : 0.5748235060305532 =====\n",
      "===== EPOCH : 16 ===== LOSS : 0.5676294866437493 =====\n",
      "===== EPOCH : 17 ===== LOSS : 0.5604428093800801 =====\n",
      "===== EPOCH : 18 ===== LOSS : 0.5532724547265804 =====\n",
      "===== EPOCH : 19 ===== LOSS : 0.5461277526034317 =====\n",
      "===== EPOCH : 20 ===== LOSS : 0.5390191974583677 =====\n",
      "===== EPOCH : 21 ===== LOSS : 0.531959969915474 =====\n",
      "===== EPOCH : 22 ===== LOSS : 0.5249677551449166 =====\n",
      "===== EPOCH : 23 ===== LOSS : 0.5180662560659016 =====\n",
      "===== EPOCH : 24 ===== LOSS : 0.511285110083566 =====\n",
      "===== EPOCH : 25 ===== LOSS : 0.5046566219642452 =====\n",
      "===== EPOCH : 26 ===== LOSS : 0.49820907058867175 =====\n",
      "===== EPOCH : 27 ===== LOSS : 0.4919593664455482 =====\n",
      "===== EPOCH : 28 ===== LOSS : 0.48590950750717465 =====\n",
      "===== EPOCH : 29 ===== LOSS : 0.4800488748435267 =====\n",
      "===== EPOCH : 30 ===== LOSS : 0.4743601101177224 =====\n",
      "===== EPOCH : 31 ===== LOSS : 0.4688247603413808 =====\n",
      "===== EPOCH : 32 ===== LOSS : 0.46342660354315884 =====\n",
      "===== EPOCH : 33 ===== LOSS : 0.4581527377139294 =====\n",
      "===== EPOCH : 34 ===== LOSS : 0.45299338486548035 =====\n",
      "===== EPOCH : 35 ===== LOSS : 0.4479412321653363 =====\n",
      "===== EPOCH : 36 ===== LOSS : 0.44299074740414596 =====\n",
      "===== EPOCH : 37 ===== LOSS : 0.4381376262245256 =====\n",
      "===== EPOCH : 38 ===== LOSS : 0.4333783917901299 =====\n",
      "===== EPOCH : 39 ===== LOSS : 0.4287101202805921 =====\n",
      "===== EPOCH : 40 ===== LOSS : 0.4241302576388084 =====\n",
      "===== EPOCH : 41 ===== LOSS : 0.419636498773181 =====\n",
      "===== EPOCH : 42 ===== LOSS : 0.4152267082396998 =====\n",
      "===== EPOCH : 43 ===== LOSS : 0.41089886827681754 =====\n",
      "===== EPOCH : 44 ===== LOSS : 0.40665104483049885 =====\n",
      "===== EPOCH : 45 ===== LOSS : 0.4024813655608521 =====\n",
      "===== EPOCH : 46 ===== LOSS : 0.39838800587842854 =====\n",
      "===== EPOCH : 47 ===== LOSS : 0.39436918048204717 =====\n",
      "===== EPOCH : 48 ===== LOSS : 0.3904231386885387 =====\n",
      "===== EPOCH : 49 ===== LOSS : 0.38654816244746276 =====\n",
      "===== EPOCH : 50 ===== LOSS : 0.3827425662544484 =====\n",
      "===== EPOCH : 51 ===== LOSS : 0.37900469844178175 =====\n",
      "===== EPOCH : 52 ===== LOSS : 0.37533294344482043 =====\n",
      "===== EPOCH : 53 ===== LOSS : 0.371725724759238 =====\n",
      "===== EPOCH : 54 ===== LOSS : 0.3681815083377766 =====\n",
      "===== EPOCH : 55 ===== LOSS : 0.3646988062192744 =====\n",
      "===== EPOCH : 56 ===== LOSS : 0.3612761801796238 =====\n",
      "===== EPOCH : 57 ===== LOSS : 0.35791224520502124 =====\n",
      "===== EPOCH : 58 ===== LOSS : 0.3546056725793572 =====\n",
      "===== EPOCH : 59 ===== LOSS : 0.35135519238499163 =====\n",
      "===== EPOCH : 60 ===== LOSS : 0.3481595952302524 =====\n",
      "===== EPOCH : 61 ===== LOSS : 0.345017733046937 =====\n",
      "===== EPOCH : 62 ===== LOSS : 0.3419285188584091 =====\n",
      "===== EPOCH : 63 ===== LOSS : 0.33889092548239025 =====\n",
      "===== EPOCH : 64 ===== LOSS : 0.3359039832315853 =====\n",
      "===== EPOCH : 65 ===== LOSS : 0.3329667767540044 =====\n",
      "===== EPOCH : 66 ===== LOSS : 0.33007844126261704 =====\n",
      "===== EPOCH : 67 ===== LOSS : 0.3272381584510381 =====\n",
      "===== EPOCH : 68 ===== LOSS : 0.32444515245821703 =====\n",
      "===== EPOCH : 69 ===== LOSS : 0.321698686212395 =====\n",
      "===== EPOCH : 70 ===== LOSS : 0.3189980584776076 =====\n",
      "===== EPOCH : 71 ===== LOSS : 0.31634260179977575 =====\n",
      "===== EPOCH : 72 ===== LOSS : 0.3137316814821669 =====\n",
      "===== EPOCH : 73 ===== LOSS : 0.31116469553032267 =====\n",
      "===== EPOCH : 74 ===== LOSS : 0.3086410754278599 =====\n",
      "===== EPOCH : 75 ===== LOSS : 0.30616028740202267 =====\n",
      "===== EPOCH : 76 ===== LOSS : 0.303721833803963 =====\n",
      "===== EPOCH : 77 ===== LOSS : 0.30132525406025484 =====\n",
      "===== EPOCH : 78 ===== LOSS : 0.29897012471322837 =====\n",
      "===== EPOCH : 79 ===== LOSS : 0.29665605797378003 =====\n",
      "===== EPOCH : 80 ===== LOSS : 0.29438269841187537 =====\n",
      "===== EPOCH : 81 ===== LOSS : 0.29214971741963597 =====\n",
      "===== EPOCH : 82 ===== LOSS : 0.2899568054433026 =====\n",
      "===== EPOCH : 83 ===== LOSS : 0.2878036620711017 =====\n",
      "===== EPOCH : 84 ===== LOSS : 0.2856899845260004 =====\n",
      "===== EPOCH : 85 ===== LOSS : 0.2836154551653526 =====\n",
      "===== EPOCH : 86 ===== LOSS : 0.2815797290005279 =====\n",
      "===== EPOCH : 87 ===== LOSS : 0.27958242209106915 =====\n",
      "===== EPOCH : 88 ===== LOSS : 0.2776231018845161 =====\n",
      "===== EPOCH : 89 ===== LOSS : 0.2757012801175573 =====\n",
      "===== EPOCH : 90 ===== LOSS : 0.2738164089258607 =====\n",
      "===== EPOCH : 91 ===== LOSS : 0.27196788015982654 =====\n",
      "===== EPOCH : 92 ===== LOSS : 0.2701550279259574 =====\n",
      "===== EPOCH : 93 ===== LOSS : 0.26837713373475175 =====\n",
      "===== EPOCH : 94 ===== LOSS : 0.26663343383558474 =====\n",
      "===== EPOCH : 95 ===== LOSS : 0.26492312782287564 =====\n",
      "===== EPOCH : 96 ===== LOSS : 0.2632453880277283 =====\n",
      "===== EPOCH : 97 ===== LOSS : 0.2615993688377923 =====\n",
      "===== EPOCH : 98 ===== LOSS : 0.2599842156757689 =====\n",
      "===== EPOCH : 99 ===== LOSS : 0.25839907302089243 =====\n",
      "===== EPOCH : 100 ===== LOSS : 0.25684309150395646 =====\n"
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=3, kernel_size=3, stride=1, padding=1), # (28 - 3 + 2 * 1) / 1 + 1 = 28\n",
    "          MaxPoolLayer(input_shape=(3, 28, 28), kernel_size=3, stride=2, padding=2), # (28 - 3 + 2 * 2) / 2 + 1 = 15\n",
    "          ConvolutionalLayer(input_shape=(3, 15, 15), output_channels=4, kernel_size=3, stride=3, padding=3), # (15 - 3 + 2 * 3) / 3 + 1 = 7\n",
    "          MaxPoolLayer(input_shape=(4, 7, 7), kernel_size=3, stride=2, padding=1),  # (7 - 3 + 2 * 1) / 2 + 1 = 4\n",
    "          ReshapeLayer(input_shape=(4, 4, 4), output_shape=4*4*4),\n",
    "          DenseLayer(4*4*4, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-4))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0, 0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAADKCAYAAAA1kfEAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGT0lEQVR4nO3aMU5UaxzG4W8AQxBGrQljXIGJoabSSt2FhT01G6Cy0oaERbgIK/ZAgZnEgmYwwTHjnFvNvY0khyjfdy7v89SneCeZP/xmYNR1XVcAAIix1noAAAB1CUAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIs9HnoeVyWabTaRmPx2U0Gt31Jqii67pydXVVdnd3y9raMD4LuTXuI7cGddzm1noF4HQ6LZPJ5K+Mg6G5uLgoe3t7rWeUUtwa95tbgzr63FqvAByPx6WUUr58+VJ2dnb+fNn/xKdPn1pPqO74+Lj1hGpms1mZTCb/vr+HYLXl8+fPZXt7u/Gaep48edJ6QnVv375tPaGa5XJZvn37Nshbe/HiRVlfX2+8pp6nT5+2nlDds2fPWk+oZj6fl48fP/a6tV4BuPp6fGdnZ1AHfNc2NzdbT6ju0aNHrSdUN6Q//6y2bG9vR33YSnqtK0P5U2hNQ7y19fX1srHR61fhvfDgwYPWE6pL/F3e59byfgIBAIQTgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhNm4zcPPnz+/qx2D9O7du9YTqjs4OGg9oZrFYtF6wo1evnzZekJVJycnrSdUd3193XpCNV3XtZ5wo7Ozs9YTqnr9+nXrCdWdn5+3nlDNz58/ez/rG0AAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCbNzm4dPT0/Lw4cO72jI4b968aT2hulevXrWeUM1isWg94UaHh4dlc3Oz9Yxq9vf3W0+o7vLysvWEamazWXn8+HHrGb/14cOHsrW11XpGNe/fv289obqjo6PWE6qZz+e9n/UNIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCE2ejzUNd1pZRSrq+v73TM0Mxms9YTqlssFq0nVPPr169Syn/v7yFYbZnP542X1PX9+/fWE6pL+vmyeq1DvLUfP340XlJX0vtuJenn6eq19rm1Udfjqa9fv5bJZPLny2CALi4uyt7eXusZpRS3xv3m1qCOPrfWKwCXy2WZTqdlPB6X0Wj01wZCS13Xlaurq7K7u1vW1obx3xBujfvIrUEdt7m1XgEIAMD9MYyPYgAAVCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAw/wAFJPjUSxNyjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_channels):\n",
    "    for j in range(conv.input_channels):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1, 28, 28)\n",
      "(500, 1, 28, 28)\n",
      "(2000, 10)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:1000])\n",
    "x_test = preprocess_whole_mnist(x_test[:200])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:1000])\n",
    "y_test = one_hot_encode(y_test[:200])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[395], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m layers \u001b[38;5;241m=\u001b[39m [ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m# (28 - 3 + 2 * 1) / 1 + 1 = 28\u001b[39;00m\n\u001b[0;32m      2\u001b[0m           MaxPoolLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;66;03m# (28 - 3 + 2 * 2) / 2 + 1 = 15\u001b[39;00m\n\u001b[0;32m      3\u001b[0m           ConvolutionalLayer(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), \u001b[38;5;66;03m# (15 - 3 + 2 * 3) / 3 + 1 = 7\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m           DenseLayer(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m      9\u001b[0m           Softmax()]\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(layers\u001b[38;5;241m=\u001b[39mlayers, loss_function\u001b[38;5;241m=\u001b[39mCCE_Loss(), optimizer\u001b[38;5;241m=\u001b[39mOptimizer_SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-3\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Grgo\\Faks\\Python\\DLFS\\dlfs\\model.py:117\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, X, y, epochs, print_every)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03mTrain the model.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_every:\n",
      "File \u001b[1;32md:\\Grgo\\Faks\\Python\\DLFS\\dlfs\\model.py:47\u001b[0m, in \u001b[0;36mModel._forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Forward data through all the layers\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Output of the model is the output of the last layer\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "Cell \u001b[1;32mIn[387], line 77\u001b[0m, in \u001b[0;36mMaxPoolLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     74\u001b[0m axis_1_end \u001b[38;5;241m=\u001b[39m axis_1_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding:\n\u001b[1;32m---> 77\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[i, j]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\numpy\\lib\\arraypad.py:801\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    798\u001b[0m padded, original_area_slice \u001b[38;5;241m=\u001b[39m _pad_simple(array, pad_width)\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# And prepare iteration over all dimensions\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# (zipping may be more readable than using enumerate)\u001b[39;00m\n\u001b[1;32m--> 801\u001b[0m axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(padded\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    804\u001b[0m     values \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=3, kernel_size=3, stride=1, padding=1), # (28 - 3 + 2 * 1) / 1 + 1 = 28\n",
    "          MaxPoolLayer(input_shape=(3, 28, 28), kernel_size=3, stride=2, padding=2), # (28 - 3 + 2 * 2) / 2 + 1 = 15\n",
    "          ConvolutionalLayer(input_shape=(3, 15, 15), output_channels=4, kernel_size=3, stride=3, padding=3), # (15 - 3 + 2 * 3) / 3 + 1 = 7\n",
    "          MaxPoolLayer(input_shape=(4, 7, 7), kernel_size=3, stride=2, padding=1),  # (7 - 3 + 2 * 1) / 2 + 1 = 4\n",
    "          ReshapeLayer(input_shape=(4, 4, 4), output_shape=4*4*4),\n",
    "          DenseLayer(4*4*4, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Softmax()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=5e-3))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [0.93864351 0.92273636 0.92122213 0.90093836 0.95721841 0.88962394\n",
      " 0.91919267 0.91743006 0.93589677 0.92453347]\n",
      "y_pred: [0.91296296 0.91701034 0.90411604 0.89345348 0.95762592 0.90553913\n",
      " 0.93279268 0.94281507 0.91805886 0.91726271]\n",
      "y_pred: [0.92130705 0.91980701 0.9153132  0.91055999 0.95512557 0.89728336\n",
      " 0.93173091 0.93362435 0.93324631 0.93191062]\n",
      "y_pred: [0.91420684 0.91549435 0.88990092 0.91035658 0.93913212 0.90041341\n",
      " 0.92616657 0.90597346 0.93660359 0.92560592]\n",
      "y_pred: [0.93440449 0.91138932 0.92314021 0.89063282 0.9602029  0.89220994\n",
      " 0.90916771 0.95822361 0.92225676 0.94156954]\n",
      "y_pred: [0.94249713 0.93717342 0.91618339 0.88090015 0.94901532 0.8863731\n",
      " 0.91839862 0.89325683 0.93118033 0.91995805]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred.reshape(-1))}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
