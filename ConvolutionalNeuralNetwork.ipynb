{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "- operation from the field of digital signal processing\n",
    "\n",
    "- 2D convolution uses two matrices, input and kernel, to produce some output\n",
    "\n",
    "- a kernel matrix is slid over the input matrix, doing element-wise multiplication and summing\n",
    "\n",
    "- kernel can be thought of as a filter, and the result of the operation is a filtered image\n",
    "\n",
    "- depending on the kernel, there are many use cases: \n",
    "    - blurring\n",
    "    - smoothing\n",
    "    - edge detection\n",
    "    - sharpening\n",
    "    - feature detection\n",
    "    - noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ValidConvolution](img/conv_valid.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FullConvolution](img/conv_full.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid vs. full convolution\n",
    "\n",
    "- **valid**\n",
    "    - kernel is slid within borders of the input matrix\n",
    "    - kernel and input overlap completely\n",
    "    - output matrix is smaller in size compared to input matrix\n",
    "\n",
    "- **full**\n",
    "    - kernel is slid outside the borders of the input matrix\n",
    "    - kernel and input overlap partially at borders\n",
    "    - region outside of borders is padded with zeros\n",
    "    - output is larger in size compared to input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlation vs. Convolution\n",
    "\n",
    "- Cross Correlation is sliding a kernel over the input matrix (denoted using $\\star$ symbol)\n",
    "\n",
    "- Convolution is sliding a *180 degrees rotated* kernel over the input matrix (denoted using $\\ast$ symbol)\n",
    "\n",
    "- this subtle difference is observed in backpropagation of the convolutional layer\n",
    "\n",
    "- Cross Correlation is used primarily in equations and code throughout this notebook, but the same can be achieved with Convolution with minor changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "- step size of kernel when sliding over the input matrix\n",
    "\n",
    "- affects output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stride](img/conv_stride.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output size formula (for square matrices)\n",
    "\n",
    "- $ \\text{valid} = \\lfloor \\frac{\\text{input size} - \\text{kernel size}}{\\text{stride}} \\rfloor + 1$\n",
    "\n",
    "- $\\text{full} = \\lfloor \\frac{\\text{input size} + \\text{kernel size}}{\\text{stride}} \\rfloor - 1$\n",
    "\n",
    "- $\\lfloor \\rfloor$ denotes the floor function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation for convolutional layer\n",
    "\n",
    "- input matrix $X$\n",
    "\n",
    "- kernel matrix $k$\n",
    "\n",
    "- output matrix $Y$\n",
    "\n",
    "$$Y = X \\star_{\\text{valid}} k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward propagation for convolutional layer\n",
    "\n",
    "- accumulated gradient from other layers $\\delta$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to input matrix $\\frac{\\partial L}{\\partial X}$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to kernel $\\frac{\\partial L}{\\partial k}$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X} = \\delta \\ast_{\\text{full}} k \\quad \\quad \\frac{\\partial L}{\\partial k} = X \\star_{\\text{valid}} \\delta $$\n",
    "\n",
    "- if stride greater than 1 is present, $\\delta$ needs to be dilated and padded to match shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def convolve2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for convolving 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of convolution.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    # Flip the kernel for convolution\n",
    "    kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    if mode == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "    \n",
    "    elif mode == 'full':\n",
    "\n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        # Pad input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.   4.  -9. -12.]\n",
      " [  7.   6.  -5. -11.]\n",
      " [  9.   8.  -6.  -7.]\n",
      " [  7.   4.  -8.  -7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='valid')\n",
    "# It is noticable that the rotation of kernel from convolution does not yield the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.  -1.   3.  -1.  -5.  -4.   5.   6.]\n",
      " [ -7.  -3.   6.   0.  -8. -10.   9.  13.]\n",
      " [-12.  -7.  11.   4.  -9. -12.  10.  15.]\n",
      " [-10.  -8.   7.   6.  -5. -11.   8.  13.]\n",
      " [-12.  -9.   9.   8.  -6.  -7.   9.   8.]\n",
      " [-10.  -6.   7.   4.  -8.  -7.  11.   9.]\n",
      " [ -9.  -4.   8.   3.  -7.  -4.   8.   5.]\n",
      " [ -3.  -1.   3.   0.  -3.  -2.   3.   3.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='full')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross correlation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for cross correlating 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of cross correlation.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if mode == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif mode == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid cross correlation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.  -4.   9.  12.]\n",
      " [ -7.  -6.   5.  11.]\n",
      " [ -9.  -8.   6.   7.]\n",
      " [ -7.  -4.   8.   7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = cross_correlate2d(x, kernel, mode='valid')\n",
    "# Using cross correlation which does not rotate the kernel yields the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(arr: np.ndarray, stride: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expands boundaries of an array by adding rows and columns of zeros between array elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to dilate.\n",
    "\n",
    "    stride : int\n",
    "        Number of zeroes added between a pair of elements.\n",
    "        NOTE: stride - 1 zeros are added between elements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dilated_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Create a new array with appropriate size for dilation\n",
    "    dilated_shape = (arr.shape[0] - 1) * stride + 1, (arr.shape[1] - 1) * stride + 1\n",
    "    dilated = np.zeros(dilated_shape)\n",
    "    \n",
    "    # Place the original array elements into the dilated array\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            dilated[i * stride, j * stride] = arr[i, j]\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "def pad_to_shape(arr: np.ndarray, target_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds padding to array so it matches target shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to pad.\n",
    "\n",
    "    target_shape : tuple\n",
    "        Shape of the array after padding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padded_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Calculate padding needed\n",
    "    pad_height = target_shape[0] - arr.shape[0]\n",
    "    pad_width = target_shape[1] - arr.shape[1]\n",
    "    \n",
    "    if pad_height < 0 or pad_width < 0:\n",
    "        raise ValueError(\"Target shape must be larger than the array shape.\")\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilate and pad example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilated:\n",
      "[[1. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [3. 0. 4.]]\n",
      "Dilated and padded:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 4. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "dilated = dilate(x, 2)\n",
    "print(f'Dilated:\\n{dilated}')\n",
    "\n",
    "dilated_padded = pad_to_shape(dilated, (5, 5))\n",
    "print(f'Dilated and padded:\\n{dilated_padded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_channels: int, kernel_size: int, stride: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (channels, height, width).\n",
    "\n",
    "        output_channels : int\n",
    "            Depth of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, a square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "        \"\"\"\n",
    "        # Unpack the input_shape tuple\n",
    "        input_channels, input_height, input_width = input_shape\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Calculate output height and width\n",
    "        output_height = int(floor((input_height - kernel_size) / stride) + 1) \n",
    "        output_width = int(floor((input_width - kernel_size) / stride) + 1)\n",
    "\n",
    "        # Create output and kernel shapes\n",
    "        self.output_shape = (output_channels, output_height, output_width)\n",
    "        self.kernels_shape = (output_channels, input_channels, kernel_size, kernel_size)\n",
    "\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Store inputs for later use\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_channels, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Add bias to output\n",
    "        self.output += self.biases\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "                    # Output is the cross correlation in valid mode between the input and kernel\n",
    "                    self.output[i, j] += signal.correlate2d(self.inputs[i, k], self.kernels[j, k], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Initialize gradient attributes\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Gradient with respect to biases is the sum of deltas\n",
    "            self.dbiases += delta[i]\n",
    "\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "\n",
    "                    if self.stride == 1:\n",
    "                        # Gradient with respect to kernels is the valid correlaton between input and delta\n",
    "                        self.dkernels[j, k] += signal.correlate2d(self.inputs[i, k], delta[i, j], \"valid\")\n",
    "                        # Gradient with respect to inputs is the full convolution between delta and kernel\n",
    "                        self.dinputs[i, k] += signal.convolve2d(delta[i, j], self.kernels[j, k], \"full\")\n",
    "\n",
    "                    # If stride is bigger than 1, dilation of delta is required\n",
    "                    else:\n",
    "\n",
    "                        delta_dilated = dilate(delta[i, j], stride=self.stride)\n",
    "\n",
    "                        delta_dilated_shape = delta_dilated.shape\n",
    "                        input_shape = self.inputs[i, k].shape[0]\n",
    "                        kernel_shape = self.dkernels[j, k].shape[0]\n",
    "\n",
    "                        if delta_dilated_shape == input_shape - kernel_shape + 1:\n",
    "                            # If dilated delta shape matches the needed correlation shape gradient is computed\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated, \"valid\")\n",
    "                        else:\n",
    "                            # If dilated delta shape doesn't match the needed correlation shape padding is needed\n",
    "                            new_delta_shape = (input_shape - kernel_shape + 1, input_shape - kernel_shape + 1)\n",
    "                            delta_dilated_padded = pad_to_shape(delta_dilated, new_delta_shape)\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated_padded, \"valid\")\n",
    "                            \n",
    "                        self.dkernels[j, k] += dkernel\n",
    "\n",
    "                        # Full convolution between dilated delta and kernel similar to stride=1\n",
    "                        dinput = signal.convolve2d(delta_dilated, self.kernels[j, k], \"full\")\n",
    "\n",
    "                        if dinput.shape == self.dinputs[i, k].shape:\n",
    "                            # If the shape of convolution result is equal to input gradient shape they can be summed\n",
    "                            self.dinputs[i, k] += dinput\n",
    "                        else:\n",
    "                            # If the shapes are not equal, padding of result is needed to match the input gradient shape\n",
    "                            dinput_padded = pad_to_shape(dinput, self.dinputs[i, k].shape)\n",
    "                            self.dinputs[i, k] += dinput_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts (batch_size, depth, height, width) to (batch_size, depth * height * width)\n",
    "        batch_size = inputs.shape[0]\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts (batch_size, depth * height * width) to (batch_size, depth, height, width)\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 0.6910701815822382 =====\n",
      "===== EPOCH : 20 ===== LOSS : 0.15894158820626736 =====\n",
      "===== EPOCH : 40 ===== LOSS : 0.0695328250821054 =====\n",
      "===== EPOCH : 60 ===== LOSS : 0.04257185532900938 =====\n",
      "===== EPOCH : 80 ===== LOSS : 0.029952881352214914 =====\n",
      "===== EPOCH : 100 ===== LOSS : 0.0228496257194763 =====\n"
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=5, kernel_size=3),\n",
    "          Sigmoid(),\n",
    "          ConvolutionalLayer(input_shape=(5, 26, 26), output_channels=8, kernel_size=4, stride=2),\n",
    "          ReshapeLayer(input_shape=(8, 12, 12), output_shape=8*12*12),\n",
    "          DenseLayer(8*12*12, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-4))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhkUlEQVR4nO3de3BU9f3G8WcJkXDJhWAQiBAHERIGrBQESsMlci8pF7lMqwLqFEZByzjijVbC2J9xGAJYQAsKikinIyBaB/A2CFUUCaBQg1xCBJsQbgFMNoAg7Pn94RiN3xOzSTab7H7frxn+6MPZ3U+cT/Hx5JuDx3EcRwAAwFoN6noAAABQtygDAABYjjIAAIDlKAMAAFiOMgAAgOUoAwAAWI4yAACA5SgDAABYjjIAAIDlrC0DR48elcfjUVZWVsDec+vWrfJ4PNq6dWvA3hP4OXYXoYrdrb9CqgysXLlSHo9Hu3btqutRasXBgwf10EMPqU+fPoqKipLH49HRo0er9B779+/XsGHD1KxZM8XHx2vixIk6ffp07QwMv7G7lWN366dw311JOnbsmCZMmKC4uDjFxMRo1KhR+uqrr/x+/SeffKLU1FQ1adJErVq10p///GeVlpbW4sSB17CuB8CPtm/frkWLFqlz585KSUnRnj17qvT6goIC9evXT7GxscrMzFRpaamysrL0xRdfKDs7W9dcc03tDA7rsbsIVaWlpUpLS1NxcbFmzZqlyMhILVy4UP3799eePXvUokWLX3z9nj17NHDgQKWkpGjBggUqKChQVlaWcnNz9fbbbwfpq6g5ykA9MnLkSH3zzTeKjo5WVlZWlf9AzczM1Pnz57V79261a9dOktSzZ08NHjxYK1eu1NSpU2thaoDdReh6/vnnlZubq+zsbN16662SpOHDh6tLly6aP3++MjMzf/H1s2bNUvPmzbV161bFxMRIkm644QZNmTJF7733noYMGVLrX0MghNS3Cfxx+fJlzZ49W927d1dsbKyaNm2qvn37asuWLRW+ZuHChUpKSlLjxo3Vv39/5eTkGNccOHBA48aNU3x8vKKiotSjRw+99dZblc5z4cIFHThwQEVFRZVeGx8fr+jo6Eqvq8jrr7+u9PT0sj9MJWnQoEHq2LGj1qxZU+33RXCwu+xuqArl3V23bp1uvfXWsiIgScnJyRo4cGClu1dSUqL3339fd911V1kRkKRJkyapWbNmIbW7YVcGSkpKtHz5cg0YMEBz587VnDlzdPr0aQ0dOtT1v1ZWrVqlRYsWafr06XriiSeUk5Oj2267TSdPniy7Zt++ferdu7f279+vxx9/XPPnz1fTpk01evRovfHGG784T3Z2tlJSUrRkyZJAf6nlHDt2TKdOnVKPHj2M3+vZs6c+//zzWv181By7y+6GqlDdXZ/Pp//+978V7l5eXp68Xm+Fr//iiy905coV4/XXXHONbrnllpDa3bD7NkHz5s119OjRct9jnDJlipKTk7V48WKtWLGi3PWHDx9Wbm6uEhMTJUnDhg1Tr169NHfuXC1YsECSNGPGDLVr1047d+5Uo0aNJEnTpk1TamqqHnvsMY0ZMyZIX13Fjh8/Lklq3bq18XutW7fW2bNndenSpbL5Uf+wu+xuqArV3f1htyraPUkqLCxUp06dXF9f2e5+9NFHNZ4xWMLuzkBERETZQvp8Pp09e7asuX322WfG9aNHjy5bSOn7NtirVy9t2rRJ0vfL8sEHH2jChAnyer0qKipSUVGRzpw5o6FDhyo3N1fHjh2rcJ4BAwbIcRzNmTMnsF/oz1y8eFGSXP/AjIqKKncN6id2l90NVaG6uzXdvcpeH0p7G3ZlQJJeeeUV3XzzzYqKilKLFi2UkJCgjRs3qri42Lj2pptuMrKOHTuW/VjU4cOH5TiOnnzySSUkJJT7lZGRIUk6depUrX49/mjcuLEk6dKlS8bvffvtt+WuQf3F7pbH7oaOUNzdmu5eZa8Ppb0Nu28TrF69WnfffbdGjx6tRx55RC1btlRERISeeeYZ5eXlVfn9fD6fJGnmzJkaOnSo6zUdOnSo0cyB8MNtqh9uW/3U8ePHFR8fz23Weo7dZXdDVaju7g+7VdHuSVKbNm0qfH1lu/tLr61vwq4MrFu3Tu3bt9f69evl8XjK8h/a5M/l5uYa2aFDh3TDDTdIktq3by9JioyM1KBBgwI/cIAkJiYqISHB9cEg2dnZuuWWW4I/FKqE3WV3Q1Wo7m6DBg3UtWtX193bsWOH2rdv/4s/JdOlSxc1bNhQu3bt0oQJE8ryy5cva8+ePeWy+i7svk0QEREhSXIcpyzbsWOHtm/f7nr9m2++We57T9nZ2dqxY4eGDx8uSWrZsqUGDBigZcuWuba/yp6QVpUfcamKvLw8o3GPHTtWGzZsUH5+flm2efNmHTp0SOPHjw/o5yPw2F12N1SF8u6OGzdOO3fuLFcIDh48qA8++MDYvQMHDuh///tf2f+OjY3VoEGDtHr16nI/dfDqq6+qtLQ0pHY3JO8MvPTSS3rnnXeMfMaMGUpPT9f69es1ZswYjRgxQkeOHNHSpUvVuXNn18dDdujQQampqbr//vt16dIlPfvss2rRooUeffTRsmuee+45paamqmvXrpoyZYrat2+vkydPavv27SooKNDevXsrnDU7O1tpaWnKyMio9DBLcXGxFi9eLEn6+OOPJUlLlixRXFyc4uLi9MADD5RdO3DgQEkq98jXWbNmae3atUpLS9OMGTNUWlqqefPmqWvXrrrnnnt+8bMRHOwuuxuqwnV3p02bphdffFEjRozQzJkzFRkZqQULFui6667Tww8/XO7alJQU9e/fv9zfg/D000+rT58+6t+/v6ZOnaqCggLNnz9fQ4YM0bBhw37xs+sVJ4S8/PLLjqQKf+Xn5zs+n8/JzMx0kpKSnEaNGjndunVzNmzY4EyePNlJSkoqe68jR444kpx58+Y58+fPd9q2bes0atTI6du3r7N3717js/Py8pxJkyY5rVq1ciIjI53ExEQnPT3dWbduXdk1W7ZscSQ5W7ZsMbKMjIxKv74fZnL79dPZHcdxkpKSjMxxHCcnJ8cZMmSI06RJEycuLs658847nRMnTlT62ahd7O6P2N3QEu676ziOk5+f74wbN86JiYlxmjVr5qSnpzu5ubnGdZKc/v37G/lHH33k9OnTx4mKinISEhKc6dOnOyUlJX59dn3hcZyf3NcBAADWCbszAwAAoGooAwAAWI4yAACA5SgDAABYjjIAAIDlKAMAAFjOr4cO+Xw+FRYWKjo6utyjJoGqcBxHXq9Xbdq0UYMGwemh7C4Cgd1FqPJ3d/0qA4WFhWrbtm3AhoPd8vPzdf311wfls9hdBBK7i1BV2e76VXF/6S9qAKoqmPvE7iKQ2F2Eqsr2ya8ywC0qBFIw94ndRSCxuwhVle0TBwgBALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwXMO6HiAUREREGNmcOXOMbPz48UbWrVs3I7t48WJA5gIqEx0dbWT//ve/jez99983smeeeaZWZkLo6tChg2t+++23G9ldd91lZF27djWyd955x/U9s7KyjGzz5s2VjYhq4s4AAACWowwAAGA5ygAAAJajDAAAYDmP4zhOZReVlJQoNjY2GPPUS82bNzeyM2fO+PXap556ysjcDh/apLi4WDExMUH5LNt3NzEx0ci+/vprv17bsCHni3/O9t3duXOna/7rX//ar9d/8sknRta0aVPXazt16mRk27ZtM7IFCxYY2bvvvuvXPDapbHe5MwAAgOUoAwAAWI4yAACA5SgDAABYjhNCfmjQoPqd6a9//auR7dq1y/XaDRs2VPtzADePPfZYtV/rdijss88+q8k4CHFNmjTx+9r33nvPyO644w4jq+ig6qhRo4zs73//u5H95je/MbKMjAwjW7NmjevnHDt2zDW3DXcGAACwHGUAAADLUQYAALAcZQAAAMtxgNAP06dPr/Zr3Q4fVvTELSDQCgoKqv3asWPHGhkHCO0xfPhwI2vXrp3rtV9++aWRTZw40cjOnTvn9+cvX77cyK677jojc3vKq9tffzxhwgTXzxkzZoyRnThxwp8Rwwp3BgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcP00AhLF//vOfRpaZmenXaydNmmRkTz/9tOu1Fy5cqNpgqPdatWplZBU9jtjr9RpZUVFRwGdatWqVkQ0ZMsTI3B6l3bNnT9f3fPvtt43shRdeMLJly5YZmc/nc33PUMSdAQAALEcZAADAcpQBAAAsRxkAAMByHCAEwpjbIa633nrLyEaOHGlkbdq0MbKIiIjADIaw8u233wblc/Lz842sf//+RjZixAgjmzlzput7duvWzciWLFliZFeuXDGyFStWGFmoHirkzgAAAJajDAAAYDnKAAAAlqMMAABgOQ4Q+uHaa6+t6xGAarl06ZKRFRQU1MEkCGezZ8+u6xHK2bhxo1+ZJDVsaP5rcNOmTUa2dOlSI9u8ebORffXVV/6MWO9wZwAAAMtRBgAAsBxlAAAAy1EGAACwHAcI/fCHP/yhrkcAANQCtycLDh8+3MjOnj1rZK+99pqR/f73v3f9nBMnTlRjuuDhzgAAAJajDAAAYDnKAAAAlqMMAABgOcoAAACW46cJatn58+eNbN++fXUwCVBz6enprvm//vWvIE8C1J6rV68aWXJyspF98sknRrZs2TLX9xw1alTNB6tF3BkAAMBylAEAACxHGQAAwHKUAQAALMcBwlp24cIFI8vJyamDSYCa6927t2vOAUKEu+PHjxvZgQMHjCwtLc319ampqUa2bdu2mg8WINwZAADAcpQBAAAsRxkAAMBylAEAACzHAcKfGDx4sGseFxcX3EGAWuTxePzKGjQw/1vB7TrAVsuXLzeyIUOGuF778MMPGxkHCAEAQL1BGQAAwHKUAQAALEcZAADAchwg/IkWLVq45g0b8o8J4cNxHL8yn8/n13WArbKzs40sLy/P9doOHTrU9jg1wp0BAAAsRxkAAMBylAEAACxHGQAAwHKcjAMsM3fuXCObNm1aHUyC+mzHjh1GdvLkSddrR40aZWT16el6tSU/P9/Izpw543ptTEyMkUVERBjZ1atXaz5YNXBnAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMvx0wSAZbxeb12PgBDw5ZdfGtm5c+dcr/3tb39b2+PUS8nJyUaWmJjoeq1bPnHiRCNbuXJljeeqDu4MAABgOcoAAACWowwAAGA5ygAAAJbjACEAv40fP941/7//+z8jO336dG2PA9Spe++918gqOkC4adMmIztw4EDAZ6ou7gwAAGA5ygAAAJajDAAAYDnKAAAAluMAYTV5PB4jcxynDiYBgqeiHWf37fDFF1+45iNHjjSymTNnGllWVlbAZwqWP/7xj0Y2Y8YMIysqKnJ9/Zw5c4xs9+7dNZ4rULgzAACA5SgDAABYjjIAAIDlKAMAAFiOA4TVxIEp2Gjz5s2ueXFxcZAnQV24//77XfObbrrJyJ566ikjc/tzc/78+TUfLMCSkpKMrHv37kbWsKH5r9ANGza4vmd9OizohjsDAABYjjIAAIDlKAMAAFiOMgAAgOU4QAhYxufzGZnX6zWymJgYI7vjjjtc3/Pxxx83ssLCwmpMh/rs3Llzrvn06dON7JFHHjGyzMxMI7t8+bLre7odVs3NzTWy7777zvX1PxcZGemap6SkGNlrr71mZB07djQyt//fLFy40K956hvuDAAAYDnKAAAAlqMMAABgOcoAAACWowwAAGA5fprgJ44fP+6au51Wrehk6s99/fXXNZoJCLTS0lIje/75543M7ScEKjr5zeO57fbpp58a2d13321kq1evNjK3nzCQpCZNmhjZ2rVrjezChQt+TOj+fpI0fvx4v15fVFRkZNOmTTOynJwcv96vvuHOAAAAlqMMAABgOcoAAACWowwAAGA5DhD+xH/+8x/X/MMPPzSyhIQEI5swYYKRnTlzpuaDAfXEiy++6JpXdPgW9nJ7VO+oUaOMLDU11fX1vXv3NrJf/epXRjZ58uRqTPejK1euGNlf/vIXI1u0aJGRVXSgNhRxZwAAAMtRBgAAsBxlAAAAy1EGAACwnMfx49FhJSUlio2NDcY8sEBxcbFiYmKC8lnsLgKJ3UWoqmx3uTMAAIDlKAMAAFiOMgAAgOUoAwAAWI4yAACA5SgDAABYjjIAAIDlKAMAAFiOMgAAgOUoAwAAWI4yAACA5SgDAABYjjIAAIDlKAMAAFiOMgAAgOUoAwAAWI4yAACA5SgDAABYjjIAAIDl/CoDjuPU9hywSDD3id1FILG7CFWV7ZNfZcDr9QZkGEAK7j6xuwgkdhehqrJ98jh+1E+fz6fCwkJFR0fL4/EEbDjYxXEceb1etWnTRg0aBOc7VOwuAoHdRajyd3f9KgMAACB8cYAQAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy1EGAACwHGUAAADLUQYAALCctWXg6NGj8ng8ysrKCth7bt26VR6PR1u3bg3YewI/x+4iVLG79VdIlYGVK1fK4/Fo165ddT1KrTh48KAeeugh9enTR1FRUfJ4PDp69GiV3mP//v0aNmyYmjVrpvj4eE2cOFGnT5+unYHhN3a3cuxu/cTuVi4cdjekykC42759uxYtWiSv16uUlJQqv76goED9+vXT4cOHlZmZqZkzZ2rjxo0aPHiwLl++XAsTA99jdxGq2N3vNazrAfCjkSNH6ptvvlF0dLSysrK0Z8+eKr0+MzNT58+f1+7du9WuXTtJUs+ePTV48GCtXLlSU6dOrYWpAXYXoYvd/V7Y3Rm4fPmyZs+ere7duys2NlZNmzZV3759tWXLlgpfs3DhQiUlJalx48bq37+/cnJyjGsOHDigcePGKT4+XlFRUerRo4feeuutSue5cOGCDhw4oKKiokqvjY+PV3R0dKXXVeT1119Xenp62UJK0qBBg9SxY0etWbOm2u+L4GB32d1Qxe6G/u6GXRkoKSnR8uXLNWDAAM2dO1dz5szR6dOnNXToUNfGt2rVKi1atEjTp0/XE088oZycHN122206efJk2TX79u1T7969tX//fj3++OOaP3++mjZtqtGjR+uNN974xXmys7OVkpKiJUuWBPpLLefYsWM6deqUevToYfxez5499fnnn9fq56Pm2F12N1Sxu6G/u2H3bYLmzZvr6NGjuuaaa8qyKVOmKDk5WYsXL9aKFSvKXX/48GHl5uYqMTFRkjRs2DD16tVLc+fO1YIFCyRJM2bMULt27bRz5041atRIkjRt2jSlpqbqscce05gxY4L01VXs+PHjkqTWrVsbv9e6dWudPXtWly5dKpsf9Q+7y+6GKnY39Hc37O4MRERElC2kz+fT2bNndeXKFfXo0UOfffaZcf3o0aPLFlL6vs316tVLmzZtkiSdPXtWH3zwgSZMmCCv16uioiIVFRXpzJkzGjp0qHJzc3Xs2LEK5xkwYIAcx9GcOXMC+4X+zMWLFyXJdemioqLKXYP6id1ld0MVuxv6uxt2ZUCSXnnlFd18882KiopSixYtlJCQoI0bN6q4uNi49qabbjKyjh07lv1oyeHDh+U4jp588kklJCSU+5WRkSFJOnXqVK1+Pf5o3LixJOnSpUvG73377bflrkH9xe6Wx+6GDna3vFDb3bD7NsHq1at19913a/To0XrkkUfUsmVLRURE6JlnnlFeXl6V38/n80mSZs6cqaFDh7pe06FDhxrNHAg/3Kb64bbVTx0/flzx8fEhcavKZuwuuxuq2N3Q392wKwPr1q1T+/bttX79enk8nrL8hzb5c7m5uUZ26NAh3XDDDZKk9u3bS5IiIyM1aNCgwA8cIImJiUpISHB9MEh2drZuueWW4A+FKmF32d1Qxe6G/u6G3bcJIiIiJEmO45RlO3bs0Pbt212vf/PNN8t97yk7O1s7duzQ8OHDJUktW7bUgAEDtGzZMtf2V9lTpqryIy5VkZeXZzTusWPHasOGDcrPzy/LNm/erEOHDmn8+PEB/XwEHrvL7oYqdjf0dzck7wy89NJLeuedd4x8xowZSk9P1/r16zVmzBiNGDFCR44c0dKlS9W5c2eVlpYar+nQoYNSU1N1//3369KlS3r22WfVokULPfroo2XXPPfcc0pNTVXXrl01ZcoUtW/fXidPntT27dtVUFCgvXv3Vjhrdna20tLSlJGRUelhluLiYi1evFiS9PHHH0uSlixZori4OMXFxemBBx4ou3bgwIGSVO6xmbNmzdLatWuVlpamGTNmqLS0VPPmzVPXrl11zz33/OJnIzjYXXY3VLG7Yb67Tgh5+eWXHUkV/srPz3d8Pp+TmZnpJCUlOY0aNXK6devmbNiwwZk8ebKTlJRU9l5HjhxxJDnz5s1z5s+f77Rt29Zp1KiR07dvX2fv3r3GZ+fl5TmTJk1yWrVq5URGRjqJiYlOenq6s27durJrtmzZ4khytmzZYmQZGRmVfn0/zOT266ezO47jJCUlGZnjOE5OTo4zZMgQp0mTJk5cXJxz5513OidOnKj0s1G72N0fsbuhhd39UTjvrsdxfnJfBwAAWCfszgwAAICqoQwAAGA5ygAAAJajDAAAYDnKAAAAlvPrOQM+n0+FhYWKjo4u93QpoCocx5HX61WbNm3UoEFweii7i0BgdxGq/N1dv8pAYWGh2rZtG7DhYLf8/Hxdf/31QfksdheBxO4iVFW2u35V3Ojo6IANBARzn9hdBBK7i1BV2T75VQa4RYVACuY+sbsIJHYXoaqyfeIAIQAAlqMMAABgOcoAAACWowwAAGA5ygAAAJajDAAAYDnKAAAAlqMMAABgOcoAAACWowwAAGA5ygAAAJajDAAAYDnKAAAAlqMMAABgOcoAAACWowwAAGA5ygAAAJajDAAAYLmGdT1AuHMcx8i8Xq/rtWlpaUa2e/fugM8EezzxxBNG1qVLFyO78847gzEOgHqKOwMAAFiOMgAAgOUoAwAAWI4yAACA5ThAGEDNmjUzMp/PZ2RNmjRxfX3Xrl2NjAOEqImxY8caWWRkZB1MAlRNv379jGzdunVGNnz4cCPjz82q484AAACWowwAAGA5ygAAAJajDAAAYDkOEAbQgw8+6Nd1xcXFrvm2bdsCOQ7g+rTL+Pj4OpgEqJrk5GQja9GihZH96U9/MjIOEFYddwYAALAcZQAAAMtRBgAAsBxlAAAAy3GAMIBGjx7t13UXLlxwzQ8fPhzAaQApKSnJr+saN25sZBcvXgz0OECNeDyeuh4hbHFnAAAAy1EGAACwHGUAAADLUQYAALAcZQAAAMvx0wTVlJiYaGSdO3f267Vr1qwJ9DiAq3fffdfI7r33XiNz+7vj3V4L1CXHcYwsJSWlDiYJP9wZAADAcpQBAAAsRxkAAMBylAEAACzHAcJquv32243M7ZGubo4cORLocQBX27ZtM7L77rvPyNwOv3KAEPWN2+OI+/btWweThB/uDAAAYDnKAAAAlqMMAABgOcoAAACW4wAhEMY+/PBDI3N7itttt91mZAsXLqyVmQB/rF+/3sj+8Y9/GJnbPqPquDMAAIDlKAMAAFiOMgAAgOUoAwAAWI4DhEAYKykpqesRgGopKioyMrcnELqZOnWqkb3wwgs1nimccWcAAADLUQYAALAcZQAAAMtRBgAAsBxlAAAAy/HTBNX04IMP1vUIQKV8Pp+RnT9/3shuvPHGYIwD1Mj+/fuNrFOnTnUwSfjhzgAAAJajDAAAYDnKAAAAlqMMAABgOQ4QVlPTpk3regSgUl6v18heffVVI7vvvvuMbODAgUa2efPmwAwGVMNHH31kZMnJyXUwSfjhzgAAAJajDAAAYDnKAAAAlqMMAABgOQ4Q+iEyMtLIGjQwe5Tb37Xtln333XeBGQyoBrdDWG4HCN0OZnGAEPWN4zh1PUJY4M4AAACWowwAAGA5ygAAAJajDAAAYDkOEPrhrrvuMrKEhAQjczvIUlpaamTLli0LzGBANezbt8+v61JTU43sueeeC/Q4QI24HdKeMmWKkb3wwgvBGCdkcWcAAADLUQYAALAcZQAAAMtRBgAAsBwHCP3wu9/9rtqvPXfuXAAnAWrO7QBhdna2kU2YMMHIXnrpJdf3fP/992s+GFANPIEwMLgzAACA5SgDAABYjjIAAIDlKAMAAFiOMgAAgOX4aQI/3HzzzdV+LY8eRn1z9epVI3N7zPCqVauMrF+/fq7vyU8TIBhOnz5tZG6PI0bVcWcAAADLUQYAALAcZQAAAMtRBgAAsJzH8eNZjiUlJYqNjQ3GPPXSwYMHjezGG2/067WdOnUysry8vBrPFMqKi4sVExMTlM+yfXf91bhxYyM7cuSIkVX0z7JLly5GFo57zu7Wre7duxvZjh07jOzzzz83sltvvbVWZgoVle0udwYAALAcZQAAAMtRBgAAsBxlAAAAy/EEwlrmdtAwHA9WIbRdvHjRyJYuXWpks2fPdn19z549jYw9RzDwBMLA4M4AAACWowwAAGA5ygAAAJajDAAAYDkOENaytWvXGhlPFUMoOHnypN/XJicn1+IkQMXcHqJ77bXX+pVJUlFRUcBnCkXcGQAAwHKUAQAALEcZAADAcpQBAAAsxwFCAK7efvttI7t69arrtdOmTTOyjIyMgM8Eu+3evdvI9uzZY2Ruf9Vxu3btXN+TA4Tf484AAACWowwAAGA5ygAAAJajDAAAYDnKAAAAluOnCWrZrl276noEoFoKCwuN7KuvvnK9NioqqrbHAVx9+eWXRtatW7c6mCS0cWcAAADLUQYAALAcZQAAAMtRBgAAsBwHCP0wefJkI3v33XeNrGnTpkb2t7/9rVZmAmpbXFyckbVq1cr12hUrVtTyNIC7jz/+2MgmTpxoZG6P15ak6667LuAzhSLuDAAAYDnKAAAAlqMMAABgOcoAAACW4wChHz799FMji42NrYNJgOA5deqUkbH3qG/27dtnZG67O3z48GCME7K4MwAAgOUoAwAAWI4yAACA5SgDAABYjgOEAICQtW3bNiPjqYJVx50BAAAsRxkAAMBylAEAACxHGQAAwHKUAQAALEcZAADAcpQBAAAsRxkAAMBylAEAACxHGQAAwHKUAQAALEcZAADAcpQBAAAsRxkAAMByfpUBx3Fqew5YJJj7xO4ikNhdhKrK9smvMuD1egMyDCAFd5/YXQQSu4tQVdk+eRw/6qfP51NhYaGio6Pl8XgCNhzs4jiOvF6v2rRpowYNgvMdKnYXgcDuIlT5u7t+lQEAABC+OEAIAIDlKAMAAFiOMgAAgOUoAwAAWI4yAACA5SgDAABYjjIAAIDl/h91FxnhKlGxfAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0, 0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_channels):\n",
    "    for j in range(conv.input_channels):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28)\n",
      "(500, 1, 28, 28)\n",
      "(1000, 10)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:1000])\n",
    "x_test = preprocess_whole_mnist(x_test[:500])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:1000])\n",
    "y_test = one_hot_encode(y_test[:500])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 2399.2808465673215 =====\n",
      "===== EPOCH : 10 ===== LOSS : 2295.2190322160673 =====\n",
      "===== EPOCH : 20 ===== LOSS : 2283.2880018153696 =====\n",
      "===== EPOCH : 30 ===== LOSS : 2272.911104701985 =====\n",
      "===== EPOCH : 40 ===== LOSS : 2262.553274767808 =====\n",
      "===== EPOCH : 50 ===== LOSS : 2252.122617660025 =====\n"
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=5, kernel_size=3, stride=2),\n",
    "          Sigmoid(),\n",
    "          ReshapeLayer(input_shape=(5, 13, 13), output_shape=5*13*13),\n",
    "          DenseLayer(5*13*13, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Softmax()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=5e-2))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred[0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
