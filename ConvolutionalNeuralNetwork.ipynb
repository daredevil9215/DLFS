{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "- operation from the field of digital signal processing\n",
    "\n",
    "- 2D convolution uses two matrices, input and kernel, to produce some output\n",
    "\n",
    "- a kernel matrix is slid over the input matrix, doing element-wise multiplication and summing\n",
    "\n",
    "- kernel can be thought of as a filter, and the result of the operation is a filtered image\n",
    "\n",
    "- depending on the kernel, there are many use cases: \n",
    "    - blurring\n",
    "    - smoothing\n",
    "    - edge detection\n",
    "    - sharpening\n",
    "    - feature detection\n",
    "    - noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ValidConvolution](img/conv_valid.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FullConvolution](img/conv_full.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid vs. full convolution\n",
    "\n",
    "- **valid**\n",
    "    - kernel is slid within borders of the input matrix\n",
    "    - kernel and input overlap completely\n",
    "    - output matrix is smaller in size compared to input matrix\n",
    "\n",
    "- **full**\n",
    "    - kernel is slid outside the borders of the input matrix\n",
    "    - kernel and input overlap partially at borders\n",
    "    - region outside of borders is padded with zeros\n",
    "    - output is larger in size compared to input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlation vs. Convolution\n",
    "\n",
    "- Cross Correlation is sliding a kernel over the input matrix (denoted using $\\star$ symbol)\n",
    "\n",
    "- Convolution is sliding a *180 degrees rotated* kernel over the input matrix (denoted using $\\ast$ symbol)\n",
    "\n",
    "- this subtle difference is observed in backpropagation of the convolutional layer\n",
    "\n",
    "- Cross Correlation is used primarily in equations and code throughout this notebook, but the same can be achieved with Convolution with minor changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "- step size of kernel when sliding over the input matrix\n",
    "\n",
    "- affects output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stride](img/conv_stride.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output size formula (for square matrices)\n",
    "\n",
    "- $ \\text{valid} = \\lfloor \\frac{\\text{input size} - \\text{kernel size}}{\\text{stride}} \\rfloor + 1$\n",
    "\n",
    "- $\\text{full} = \\lfloor \\frac{\\text{input size} + \\text{kernel size}}{\\text{stride}} \\rfloor - 1$\n",
    "\n",
    "- $\\lfloor \\rfloor$ denotes the floor function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation for convolutional layer\n",
    "\n",
    "- input matrix $X$\n",
    "\n",
    "- kernel matrix $k$\n",
    "\n",
    "- output matrix $Y$\n",
    "\n",
    "$$Y = X \\star_{\\text{valid}} k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward propagation for convolutional layer\n",
    "\n",
    "- accumulated gradient from other layers $\\delta$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to input matrix $\\frac{\\partial L}{\\partial X}$\n",
    "\n",
    "- gradient of the loss function $L$ with respect to kernel $\\frac{\\partial L}{\\partial k}$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X} = \\delta \\ast_{\\text{full}} k \\quad \\quad \\frac{\\partial L}{\\partial k} = X \\star_{\\text{valid}} \\delta $$\n",
    "\n",
    "- if stride greater than 1 is present, $\\delta$ needs to be dilated and padded to match shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def convolve2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for convolving 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of convolution.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    # Flip the kernel for convolution\n",
    "    kernel_flipped = np.rot90(kernel, 2) # or kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    if mode == 'valid':\n",
    "    \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the convolution\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "    \n",
    "    elif mode == 'full':\n",
    "\n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "\n",
    "        # Pad input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km - 1, km - 1), (kn - 1, kn - 1)), mode='constant')\n",
    "\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel_flipped)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.   4.  -9. -12.]\n",
      " [  7.   6.  -5. -11.]\n",
      " [  9.   8.  -6.  -7.]\n",
      " [  7.   4.  -8.  -7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='valid')\n",
    "# It is noticable that the rotation of kernel from convolution does not yield the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full convolution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.  -1.   3.  -1.  -5.  -4.   5.   6.]\n",
      " [ -7.  -3.   6.   0.  -8. -10.   9.  13.]\n",
      " [-12.  -7.  11.   4.  -9. -12.  10.  15.]\n",
      " [-10.  -8.   7.   6.  -5. -11.   8.  13.]\n",
      " [-12.  -9.   9.   8.  -6.  -7.   9.   8.]\n",
      " [-10.  -6.   7.   4.  -8.  -7.  11.   9.]\n",
      " [ -9.  -4.   8.   3.  -7.  -4.   8.   5.]\n",
      " [ -3.  -1.   3.   0.  -3.  -2.   3.   3.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = convolve2d(x, kernel, mode='full')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross correlation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate2d(matrix: np.ndarray, kernel: np.ndarray, mode: Literal['valid', 'full'] = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for cross correlating 2D input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : np.ndarray\n",
    "        Input array.\n",
    "\n",
    "    kernel : np.ndarray\n",
    "        Array which slides over the input array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : np.ndarray\n",
    "        Result of cross correlation.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the input matrix and kernel\n",
    "    m, n = matrix.shape\n",
    "    km, kn = kernel.shape\n",
    "\n",
    "    if mode == 'valid':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m - km + 1\n",
    "        output_dim_n = n - kn + 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    elif mode == 'full':\n",
    "        \n",
    "        # Calculate the dimensions of the output matrix\n",
    "        output_dim_m = m + km - 1\n",
    "        output_dim_n = n + kn - 1\n",
    "        output = np.zeros((output_dim_m, output_dim_n))\n",
    "        \n",
    "        # Pad the input matrix with zeros\n",
    "        padded_matrix = np.pad(matrix, ((km-1, km-1), (kn-1, kn-1)), mode='constant')\n",
    "\n",
    "        # Perform the cross-correlation\n",
    "        for i in range(output_dim_m):\n",
    "            for j in range(output_dim_n):\n",
    "                # Element-wise multiplication and summation\n",
    "                region = padded_matrix[i:i+km, j:j+kn]\n",
    "                output[i, j] = np.sum(region * kernel)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid cross correlation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.  -4.   9.  12.]\n",
      " [ -7.  -6.   5.  11.]\n",
      " [ -9.  -8.   6.   7.]\n",
      " [ -7.  -4.   8.   7.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3, 1, 0, 2, 5, 6],\n",
    "              [4, 2, 1, 1, 4 ,7],\n",
    "              [5, 4 ,0, 0, 1, 2],\n",
    "              [1, 2, 2, 1, 3, 4],\n",
    "              [6, 3, 1, 0, 5, 2],\n",
    "              [3, 1, 0, 1, 3, 3]])\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "\n",
    "y = cross_correlate2d(x, kernel, mode='valid')\n",
    "# Using cross correlation which does not rotate the kernel yields the same result as the first animation\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(arr: np.ndarray, stride: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expands boundaries of an array by adding rows and columns of zeros between array elements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to dilate.\n",
    "\n",
    "    stride : int\n",
    "        Number of zeroes added between a pair of elements.\n",
    "        NOTE: stride - 1 zeros are added between elements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dilated_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Create a new array with appropriate size for dilation\n",
    "    dilated_shape = (arr.shape[0] - 1) * stride + 1, (arr.shape[1] - 1) * stride + 1\n",
    "    dilated = np.zeros(dilated_shape)\n",
    "    \n",
    "    # Place the original array elements into the dilated array\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            dilated[i * stride, j * stride] = arr[i, j]\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "def pad_to_shape(arr: np.ndarray, target_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adds padding to array so it matches target shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Array to pad.\n",
    "\n",
    "    target_shape : tuple\n",
    "        Shape of the array after padding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    padded_arr : np.ndarray\n",
    "    \"\"\"\n",
    "    # Calculate padding needed\n",
    "    pad_height = target_shape[0] - arr.shape[0]\n",
    "    pad_width = target_shape[1] - arr.shape[1]\n",
    "    \n",
    "    if pad_height < 0 or pad_width < 0:\n",
    "        raise ValueError(\"Target shape must be larger than the array shape.\")\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilate and pad example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilated:\n",
      "[[1. 0. 2.]\n",
      " [0. 0. 0.]\n",
      " [3. 0. 4.]]\n",
      "Dilated and padded:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 4. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "dilated = dilate(x, 2)\n",
    "print(f'Dilated:\\n{dilated}')\n",
    "\n",
    "dilated_padded = pad_to_shape(dilated, (5, 5))\n",
    "print(f'Dilated and padded:\\n{dilated_padded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from dlfs.base import Layer\n",
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_channels: int, kernel_size: int, stride: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Convolutional layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : tuple\n",
    "            Dimension of a single sample processed by the layer. For images it's (channels, width, height).\n",
    "\n",
    "        output_channels : int\n",
    "            Number of channels of the output array.\n",
    "\n",
    "        kernel_size : int\n",
    "            Dimension of a single kernel, square array of shape (kernel_size, kernel_size).\n",
    "\n",
    "        stride : int, default=1\n",
    "            Step size at which the kernel moves across the input.\n",
    "        \"\"\"\n",
    "        # Unpack input_shape tuple\n",
    "        input_channels, input_width, input_height = input_shape\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Calculate output width and height\n",
    "        output_width = int(floor((input_width - kernel_size) / stride) + 1)\n",
    "        output_height = int(floor((input_height - kernel_size) / stride) + 1) \n",
    "\n",
    "        # Create output and kernel shapes\n",
    "        self.output_shape = (output_channels, output_width, output_height)\n",
    "        self.kernels_shape = (output_channels, input_channels, kernel_size, kernel_size)\n",
    "\n",
    "        # Initialize layer parameters\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Forward pass using the convolutional layer. Creates output attribute.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Store inputs for later use\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, output_channels, height, width)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Add bias to output\n",
    "        self.output += self.biases\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "                    # Output is the cross correlation in valid mode between the input and kernel\n",
    "                    self.output[i, j] += signal.correlate2d(self.inputs[i, k], self.kernels[j, k], mode=\"valid\")[::self.stride, ::self.stride]\n",
    "            \n",
    "    def backward(self, delta: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Backward pass using the convolutional layer. Creates gradient attributes with respect to kernels, biases and inputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : np.ndarray\n",
    "            Accumulated gradient obtained by backpropagation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Initialize gradient attributes\n",
    "        self.dkernels = np.zeros(self.kernels.shape)\n",
    "        self.dbiases = np.zeros(self.biases.shape)\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "\n",
    "        # Number of samples, first dimension\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through each sample, output channel and input channel\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Gradient with respect to biases is the sum of deltas\n",
    "            self.dbiases += delta[i]\n",
    "\n",
    "            for j in range(self.output_channels):\n",
    "                for k in range(self.input_channels):\n",
    "\n",
    "                    if self.stride == 1:\n",
    "                        # Gradient with respect to kernels is the valid correlaton between input and delta\n",
    "                        self.dkernels[j, k] += signal.correlate2d(self.inputs[i, k], delta[i, j], \"valid\")\n",
    "                        # Gradient with respect to inputs is the full convolution between delta and kernel\n",
    "                        self.dinputs[i, k] += signal.convolve2d(delta[i, j], self.kernels[j, k], \"full\")\n",
    "\n",
    "                    # If stride is bigger than 1, dilation of delta is required\n",
    "                    else:\n",
    "\n",
    "                        delta_dilated = dilate(delta[i, j], stride=self.stride)\n",
    "\n",
    "                        delta_dilated_shape = delta_dilated.shape\n",
    "                        input_shape = self.inputs[i, k].shape[0]\n",
    "                        kernel_shape = self.dkernels[j, k].shape[0]\n",
    "\n",
    "                        if delta_dilated_shape == input_shape - kernel_shape + 1:\n",
    "                            # If dilated delta shape matches the needed correlation shape gradient is computed\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated, \"valid\")\n",
    "                        else:\n",
    "                            # If dilated delta shape doesn't match the needed correlation shape padding is needed\n",
    "                            new_delta_shape = (input_shape - kernel_shape + 1, input_shape - kernel_shape + 1)\n",
    "                            delta_dilated_padded = pad_to_shape(delta_dilated, new_delta_shape)\n",
    "                            dkernel = signal.correlate2d(self.inputs[i, k], delta_dilated_padded, \"valid\")\n",
    "                            \n",
    "                        self.dkernels[j, k] += dkernel\n",
    "\n",
    "                        # Full convolution between dilated delta and kernel similar to stride=1\n",
    "                        dinput = signal.convolve2d(delta_dilated, self.kernels[j, k], \"full\")\n",
    "\n",
    "                        if dinput.shape == self.dinputs[i, k].shape:\n",
    "                            # If the shape of convolution result is equal to input gradient shape they can be summed\n",
    "                            self.dinputs[i, k] += dinput\n",
    "                        else:\n",
    "                            # If the shapes are not equal, padding of result is needed to match the input gradient shape\n",
    "                            dinput_padded = pad_to_shape(dinput, self.dinputs[i, k].shape)\n",
    "                            self.dinputs[i, k] += dinput_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, output_shape) -> None:\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # converts (batch_size, channels, width, height) to (batch_size, channels * width * height)\n",
    "        batch_size = inputs.shape[0]\n",
    "        self.output = np.reshape(inputs, (batch_size, self.output_shape))\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # converts (batch_size, channels * width * height) to (batch_size, channels, width, height)\n",
    "        batch_size = delta.shape[0]\n",
    "        self.dinputs = np.reshape(delta, (batch_size, *self.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer(Layer):\n",
    "\n",
    "    def __init__(self, input_shape, kernel_size, stride):\n",
    "        \"\"\"\n",
    "        proba\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack the input_shape tuple\n",
    "        input_channels, input_width, input_height = input_shape\n",
    "\n",
    "        # Store input channels, kernel size and stride\n",
    "        self.input_channels = input_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Calculate output width and height\n",
    "        self.output_width = int(floor((input_width - kernel_size) / stride) + 1)\n",
    "        self.output_height = int(floor((input_height - kernel_size) / stride) + 1) \n",
    "\n",
    "        # Create output shape\n",
    "        self.output_shape = (self.input_channels, self.output_height, self.output_width)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # List for storing indices of max elements\n",
    "        self.max_indices = []\n",
    "        \n",
    "        # Store inputs\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Number of samples, first dimenison\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        # Output is 4D tensor of shape (n_samples, input_channels, width, height)\n",
    "        self.output = np.zeros((n_samples, *self.output_shape))\n",
    "\n",
    "        # Loop through every sample\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Add empty list to max indices for the current sample\n",
    "            self.max_indices.append([])\n",
    "\n",
    "            # Loop through every channel\n",
    "            for j in range(self.input_channels):\n",
    "\n",
    "                # Add empty list to max indices for the current channel of the current sample\n",
    "                self.max_indices[i].append([])\n",
    "\n",
    "                # Loop through each element of the output\n",
    "                for k in range(self.output_width):\n",
    "                    for l in range(self.output_height):\n",
    "                        \n",
    "                        # Initalize axis 0 start and end indices \n",
    "                        axis_0_start = k * self.stride\n",
    "                        axis_0_end = axis_0_start + self.kernel_size\n",
    "\n",
    "                        # Initalize axis 1 start and end indices\n",
    "                        axis_1_start = l*self.stride\n",
    "                        axis_1_end = axis_1_start + self.kernel_size\n",
    "\n",
    "                        # Use axis 0 and 1 indices to obtain max pooling region\n",
    "                        region = inputs[i, j, axis_0_start:axis_0_end, axis_1_start:axis_1_end]\n",
    "\n",
    "                        # Get the max element from the region, save it to output\n",
    "                        self.output[i, j, k, l] = np.max(region)\n",
    "                        \n",
    "                        # Get the index of the max element within the region (region is flattened array in this case)\n",
    "                        max_index = np.argmax(region)\n",
    "\n",
    "                        # Calculate the position of the max element within the sample\n",
    "                        max_element_position = (axis_0_start + (max_index // self.kernel_size), axis_1_start + (max_index % self.kernel_size))\n",
    "\n",
    "                        # Store the position of max element\n",
    "                        self.max_indices[i][j].append(max_element_position)\n",
    "\n",
    "    def backward(self, delta):\n",
    "\n",
    "        # Initialize input gradient\n",
    "        self.dinputs = np.zeros(self.inputs.shape)\n",
    "\n",
    "        # Number of samples, first dimenison\n",
    "        n_samples = self.inputs.shape[0]\n",
    "\n",
    "        # Loop through samples\n",
    "        for i in range(n_samples):\n",
    "            # Loop through channels\n",
    "            for j in range(self.input_channels):\n",
    "                # Loop through pairs of indices zipped with a delta value\n",
    "                for (k, l), d in zip(self.max_indices[i][j], delta[i, j].flatten()):\n",
    "                    self.dinputs[i, j, k, l] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 0.6914534467160606 =====\n",
      "===== EPOCH : 20 ===== LOSS : 0.054879376608533835 =====\n",
      "===== EPOCH : 40 ===== LOSS : 0.020531476371501524 =====\n",
      "===== EPOCH : 60 ===== LOSS : 0.011794649903090992 =====\n",
      "===== EPOCH : 80 ===== LOSS : 0.00789870093809164 =====\n",
      "===== EPOCH : 100 ===== LOSS : 0.0057829526975845535 =====\n"
     ]
    }
   ],
   "source": [
    "from dlfs.layers import DenseLayer\n",
    "from dlfs.activation import Sigmoid\n",
    "from dlfs.loss import BCE_Loss\n",
    "from dlfs.optimizers import Optimizer_SGD\n",
    "from dlfs import Model\n",
    "\n",
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=3, kernel_size=3, stride=2),\n",
    "          MaxPoolLayer(input_shape=(3, 13, 13), kernel_size=2, stride=2),\n",
    "          ReshapeLayer(input_shape=(3, 6, 6), output_shape=3*6*6),\n",
    "          DenseLayer(3*6*6, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 1),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=BCE_Loss(), optimizer=Optimizer_SGD(5e-3))\n",
    "\n",
    "model.train(x_train, y_train.reshape(-1, 1), print_every=20, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(f'Model accuracy: {np.mean(np.round(y_pred) == y_test.reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.round(y_pred[0, 0])}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of kernels learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 8))\n",
    "\n",
    "conv = model.layers[0]\n",
    "\n",
    "for i in range(conv.output_channels):\n",
    "    for j in range(conv.input_channels):\n",
    "\n",
    "        x = conv.kernels[i, j]\n",
    "        ax[i].imshow(x, cmap='gray')\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1, 28, 28)\n",
      "(500, 1, 28, 28)\n",
      "(2000, 10)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_whole_mnist(x):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    return x\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    categories = np.unique(y)\n",
    "    encoded_y = np.zeros((len(y), len(categories)))\n",
    "\n",
    "    for idx, label in enumerate(y):\n",
    "        to_encode_idx = np.argwhere(categories == label)\n",
    "        encoded_y[idx, to_encode_idx] = 1\n",
    "\n",
    "    return encoded_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_whole_mnist(x_train[:2000])\n",
    "x_test = preprocess_whole_mnist(x_test[:500])\n",
    "\n",
    "y_train = one_hot_encode(y_train[:2000])\n",
    "y_test = one_hot_encode(y_test[:500])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlfs.base import Loss, Activation\n",
    "\n",
    "class CCE_Loss(Loss):\n",
    "\n",
    "    def calculate(self, y_pred, y_true):\n",
    "        samples = range(len(y_pred))\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[samples, y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        return (-np.sum(np.log(correct_confidences)))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if(len(y_true.shape)) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples   \n",
    "\n",
    "class Softmax(Activation):\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.output = exp / np.sum(exp, axis=1, keepdims=True) \n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues) \n",
    "\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EPOCH : 0 ===== LOSS : 1551.410974980108 =====\n",
      "===== EPOCH : 10 ===== LOSS : 677.8684224993966 =====\n",
      "===== EPOCH : 20 ===== LOSS : 384.9557228987567 =====\n",
      "===== EPOCH : 30 ===== LOSS : 258.015143839117 =====\n",
      "===== EPOCH : 40 ===== LOSS : 190.60263813442188 =====\n",
      "===== EPOCH : 50 ===== LOSS : 149.72590779389202 =====\n"
     ]
    }
   ],
   "source": [
    "layers = [ConvolutionalLayer(input_shape=(1, 28, 28), output_channels=5, kernel_size=3, stride=2),\n",
    "          MaxPoolLayer(input_shape=(5, 13, 13), kernel_size=2, stride=1),\n",
    "          ReshapeLayer(input_shape=(5, 12, 12), output_shape=5*12*12),\n",
    "          DenseLayer(5*12*12, 100),\n",
    "          Sigmoid(),\n",
    "          DenseLayer(100, 10),\n",
    "          Sigmoid()]\n",
    "\n",
    "model = Model(layers=layers, loss_function=CCE_Loss(), optimizer=Optimizer_SGD(learning_rate=5e-2))\n",
    "\n",
    "model.train(x_train, y_train, print_every=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [0.93864351 0.92273636 0.92122213 0.90093836 0.95721841 0.88962394\n",
      " 0.91919267 0.91743006 0.93589677 0.92453347]\n",
      "y_pred: [0.91296296 0.91701034 0.90411604 0.89345348 0.95762592 0.90553913\n",
      " 0.93279268 0.94281507 0.91805886 0.91726271]\n",
      "y_pred: [0.92130705 0.91980701 0.9153132  0.91055999 0.95512557 0.89728336\n",
      " 0.93173091 0.93362435 0.93324631 0.93191062]\n",
      "y_pred: [0.91420684 0.91549435 0.88990092 0.91035658 0.93913212 0.90041341\n",
      " 0.92616657 0.90597346 0.93660359 0.92560592]\n",
      "y_pred: [0.93440449 0.91138932 0.92314021 0.89063282 0.9602029  0.89220994\n",
      " 0.90916771 0.95822361 0.92225676 0.94156954]\n",
      "y_pred: [0.94249713 0.93717342 0.91618339 0.88090015 0.94901532 0.8863731\n",
      " 0.91839862 0.89325683 0.93118033 0.91995805]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "i, j = 0, 0\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "for idx, x in enumerate(x_test[:6]):\n",
    "\n",
    "    img = x.reshape(28, 28)\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    ax[i, j].imshow(img, cmap='gray')\n",
    "    ax[i, j].set_xticks([])\n",
    "    ax[i, j].set_yticks([])\n",
    "    ax[i, j].set_title(f'Label: {np.argmax(y_pred.reshape(-1))}')\n",
    "\n",
    "    j += 1\n",
    "    if j % 3 == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
